{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sunday, December 3, 2023\n",
    "\n",
    "Downloaded the \"TheBloke/Python-Code-33B-GPTQ\" model yesterday ... ran a quick test this morning. It works!\n",
    "\n",
    "### Friday, November 17, 2023\n",
    "\n",
    "https://huggingface.co/TheBloke/Python-Code-33B-GPTQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You need this to just target the 4090.\n",
    "# only target the 4090 ...\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = \"TheBloke/Python-Code-33B-GPTQ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models--TheBloke--CodeLlama-34B-Instruct-GPTQ  version.txt\n",
      "models--TheBloke--Python-Code-33B-GPTQ\n"
     ]
    }
   ],
   "source": [
    "!ls /home/rob/Data2/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have activated exllama backend. Note that you can get better inference\n",
      "                    speed using exllamav2 kernel by setting `use_exllama_v2=True`.`disable_exllama` will be deprecated\n",
      "                    in future version.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.9 s, sys: 9.32 s, total: 29.3 s\n",
      "Wall time: 12.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# To use a different branch, change revision\n",
    "# For example: revision=\"gptq-4bit-128g-actorder_True\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name_or_path,\n",
    "                                             device_map=\"auto\",\n",
    "                                             trust_remote_code=False,\n",
    "                                             revision=\"main\")\n",
    "\n",
    "\n",
    "# Load time\n",
    "# CPU times: user 19.9 s, sys: 9.32 s, total: 29.3 s\n",
    "# Wall time: 12.4 s\n",
    "# 18424MiB VRAM\n",
    "\n",
    "# Download time\n",
    "# CPU times: user 1min 32s, sys: 1min 39s, total: 3min 12s\n",
    "# Wall time: 4h 37s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docker cp c9b676310ea0://home/rob/Data2/huggingface/transformers/models--TheBloke--Python-Code-33B-GPTQ /home/rob/Data3/huggingface/transformers\n",
    "# Successfully copied 16.9GB to /home/rob/Data3/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Tell me about AI\"\n",
    "prompt_template=f'''This is a conversation with your helpful AI assistant. AI assistant can generate Python Code along with necessary explanation.\n",
    "\n",
    "Context\n",
    "You are a helpful AI assistant.\n",
    "\n",
    "USER: {prompt}\n",
    "ASSISTANT:\n",
    "'''\n",
    "\n",
    "# print(\"\\n\\n*** Generate:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(prompt_template, return_tensors='pt').input_ids.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> This is a conversation with your helpful AI assistant. AI assistant can generate Python Code along with necessary explanation.\n",
      "\n",
      "Context\n",
      "You are a helpful AI assistant.\n",
      "\n",
      "USER: Tell me about AI\n",
      "ASSISTANT:\n",
      "\n",
      "Artificial Intelligence (AI) is a field of computer science that studies intelligent agents. An intelligent agent is a program that can perceive its environment, make decisions, and take actions to achieve a goal. \n",
      "\n",
      "AI researchers study various aspects of intelligent agents, such as their learning algorithms, decision-making processes, and communication skills. They also explore how AI can be applied in different fields, such as computer games, finance, and healthcare.\n",
      "\n",
      "One area of AI that has received a lot of attention recently is deep learning. Deep learning is a subfield of AI that studies neural networks, which are inspired by the structure of the brain. Deep learning algorithms have achieved impressive results in areas such as image recognition and language processing.\n",
      "\n",
      "Overall, AI is a rapidly developing field that holds promise for many exciting applications.</s>\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(inputs=input_ids, temperature=0.7, do_sample=True, top_p=0.95, top_k=40, max_new_tokens=512)\n",
    "print(tokenizer.decode(output[0]))\n",
    "\n",
    "# 19524 MiB VRAM\n",
    "\n",
    "# 9.5s\n",
    "# 14.9s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference can also be done using transformers' pipeline\n",
    "\n",
    "# print(\"*** Pipeline:\")\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=512,\n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    "    top_p=0.95,\n",
    "    top_k=40,\n",
    "    repetition_penalty=1.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a conversation with your helpful AI assistant. AI assistant can generate Python Code along with necessary explanation.\n",
      "\n",
      "Context\n",
      "You are a helpful AI assistant.\n",
      "\n",
      "USER: Tell me about AI\n",
      "ASSISTANT:\n",
      "Artificial Intelligence (AI) is a branch of computer science that studies intelligent agents. An intelligent agent is a system that perceives its environment and takes actions to achieve its goals. \n",
      "\n",
      "In the field of AI, we study how to build such intelligent agents using machines. We use various techniques such as machine learning, data mining, and logical reasoning to create algorithms that can solve complex problems.\n",
      "\n",
      "Some examples of AI applications include:\n",
      "\n",
      "1. Self-driving cars: AI systems can process large amounts of data from sensors and make decisions about how to move the car.\n",
      "\n",
      "2. Robotics: AI systems can be used to control robots, allowing them to perform tasks such as manipulating objects or navigating through obstacles.\n",
      "\n",
      "3. Drones: AI systems can help drones navigate through airspace and identify targets.\n",
      "\n",
      "4. Cybersecurity: AI systems can detect patterns in network traffic to identify potential threats.\n",
      "\n",
      "5. Healthcare: AI systems can analyze large amounts of medical data to identify patterns and improve diagnostics.\n",
      "\n",
      "The future of AI looks promising, with many new applications and technologies on the horizon. It is an exciting time to be working in this field!\n"
     ]
    }
   ],
   "source": [
    "print(pipe(prompt_template)[0]['generated_text'])\n",
    "\n",
    "# 19906 MiB VRAM\n",
    "\n",
    "# 12.9s \n",
    "# 15.2s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
