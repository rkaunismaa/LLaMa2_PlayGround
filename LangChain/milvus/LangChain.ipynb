{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saturday, February 3, 2024\n",
    "\n",
    "Re-ran the data import and it once again fails at the same fail point with the exact same message as from yesterday ... and the collection only has 49280 records.\n",
    "\n",
    "Looking at the Milvus installation instructions I can see they have changed since when I ran the install less than a week ago. At this point I am going to torch all things Milvus on this computer and then run the new install instructions...\n",
    "\n",
    "Nope! No Change! And when I force 'wtf!' as the text string, all the data loads and we end up with 205328 records which is correct. So there is definitely some issue with the data in the pandas dataframe that is causing the problem. Hmm I am going to trim the data in the text column even more to see if that makes any change in the data load.\n",
    "\n",
    "Yup! That worked! Trimming to (65535 - 8192) characters seems to have fixed the problem with the import. We now have 205328 records. Nice!\n",
    "\n",
    "\n",
    "### Friday, February 2, 2024\n",
    "\n",
    "I am getting the feeling there are bugs with Milvus. I keep getting errors like ...\n",
    "\n",
    "\"MilvusException: <MilvusException: (code=1100, message=the length (66120) of 39th string exceeds max length (65535): invalid parameter[expected=valid length string][actual=string length exceeds max length])>\"\n",
    "\n",
    "... even though I HAVE TRIMMED THE DATA TO ENSURE IT IS NOT TOO LONG! ... \n",
    "\n",
    "### Thursday, February 1, 2024\n",
    "\n",
    "[Tutorial: Building a Semantic Text Search Application](https://www.youtube.com/watch?v=Mvbc88IfAN8)\n",
    "\n",
    "The above video was very helpful for the completion of this notebook.\n",
    "\n",
    "### Wednesday, January 31, 2024\n",
    "\n",
    "mamba activate milvus\n",
    "\n",
    "https://python.langchain.com/docs/integrations/vectorstores/milvus\n",
    "\n",
    "[Building RAG Apps Without OpenAI - Part One](https://zilliz.com/blog/building-rag-apps-without-openai-part-I)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import Milvus\n",
    "# from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"data/state_of_the_union.txt\")\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to use Sentence Transformers embeddings, not OpenAI.\n",
    "\n",
    "Hmm actually it turns out we will not be using this library in this example ... but I am going to keep the code here just to make that clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rob/miniforge3/envs/milvus/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# This is their best model ...\n",
    "sentenceTransformer = SentenceTransformer('all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NFW this is gonna work ...\n",
    "# vector_db = Milvus.from_documents(\n",
    "#     docs,\n",
    "#     sentenceTransformer,\n",
    "#     connection_args={\"host\": \"127.0.0.1\", \"port\": \"19530\"},\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like [this](https://zilliz.com/blog/building-rag-apps-without-openai-part-I) could prove useful in making a RAG app with LangChain and Milvus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from milvus import default_server\n",
    "# default_server.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the embeddings we are going to use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "# is this model by default: sentence-transformers/all-mpnet-base-v2\n",
    "embeddings = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import (\n",
    "    connections,\n",
    "    utility,\n",
    "    FieldSchema, CollectionSchema, DataType,\n",
    "    Collection,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmt = \"\\n=== {:30} ===\\n\"\n",
    "search_latency_fmt = \"search latency = {:.4f}s\"\n",
    "num_entities, dim = 3000, 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== start connecting to Milvus     ===\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#################################################################################\n",
    "# 1. connect to Milvus\n",
    "# Add a new connection alias `default` for Milvus server in `localhost:19530`\n",
    "# Actually the \"default\" alias is a buildin in PyMilvus.\n",
    "# If the address of Milvus is the same as `localhost:19530`, you can omit all\n",
    "# parameters and call the method as: `connections.connect()`.\n",
    "#\n",
    "# Note: the `using` parameter of the following methods is default to \"default\".\n",
    "print(fmt.format(\"start connecting to Milvus\"))\n",
    "\n",
    "connections.connect(\"default\", host=\"localhost\", port=\"19530\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "langchainCollection = \"LangChainCollection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this can be run even if the collection does not exist\n",
    "utility.drop_collection(langchainCollection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here we no longer reference the 'langchainCollection' variable, and when we inject data, it gets injected into a collection by this name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Milvus\n",
    "\n",
    "vectordb = Milvus.from_documents(\n",
    "   {},\n",
    "   embeddings,\n",
    "   connection_args={\"host\": \"127.0.0.1\", \"port\": \"19530\"},\n",
    "   consistency_level=\"Strong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import VectorStoreRetrieverMemory\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = Milvus.as_retriever(vectordb, search_kwargs=dict(k=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = VectorStoreRetrieverMemory(retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "about_me = [\n",
    "   {\"input\": \"My favorite snack is chocolate\",\n",
    "    \"output\": \"Nice\"},\n",
    "   {\"input\": \"My favorite sport is swimming\",\n",
    "    \"output\": \"Cool\"},\n",
    "   {\"input\": \"My favorite beer is Guinness\",\n",
    "    \"output\": \"Great\"},\n",
    "   {\"input\": \"My favorite dessert is cheesecake\",\n",
    "    \"output\": \"Good to know\"},\n",
    "   {\"input\": \"My favorite musician is Taylor Swift\",\n",
    "    \"output\": \"I also love Taylor Swift\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell will inject the collection into milvus ... prior to this cell,\n",
    "# the collection does not exist.\n",
    "\n",
    "for example in about_me:\n",
    "   memory.save_context({\"input\": example[\"input\"]}, {\"output\": example[\"output\"]})\n",
    "\n",
    "   # 18.6s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: My favorite musician is Taylor Swift\n",
      "output: I also love Taylor Swift\n"
     ]
    }
   ],
   "source": [
    "print(memory.load_memory_variables({\"prompt\": \"who is my favorite musician?\"})[\"history\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not going to use OpenAI, but use LMStudio for our LLM. \n",
    "\n",
    "LMStudio is currently serving up the model \"nexusflow_nexusraven-v2-13b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rob/miniforge3/envs/milvus/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "llm = OpenAI(base_url=\"http://localhost:1234/v1\", temperature=.7,  api_key=\"NULL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rob/miniforge3/envs/milvus/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "# Using LMStudio to serve up our local openai goodness ...\n",
    "chat = ChatOpenAI(base_url=\"http://localhost:1234/v1\", temperature=.7,  api_key=\"NULL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.llms.symblai_nebula import Nebula\n",
    "# llm = Nebula(nebula_api_key=api_key)\n",
    "\n",
    "_DEFAULT_TEMPLATE = \"\"\"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
    "\n",
    "Relevant pieces of previous conversation:\n",
    "{history}\n",
    "\n",
    "(You do not need to use these pieces of information if not relevant)\n",
    "\n",
    "Current conversation:\n",
    "Human: {input}\n",
    "AI:\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "   input_variables=[\"history\", \"input\"], template=_DEFAULT_TEMPLATE\n",
    ")\n",
    "\n",
    "conversation_with_summary = ConversationChain(\n",
    "   llm=llm,\n",
    "   prompt=PROMPT,\n",
    "   memory=memory,\n",
    "   verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Relevant pieces of previous conversation:\n",
      "input: My favorite beer is Guinness\n",
      "output: Great\n",
      "\n",
      "(You do not need to use these pieces of information if not relevant)\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi Nebula, what's up?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Human: I'm feeling really down today. What should I do?\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_with_summary.predict(input=\"Hi Nebula, what's up?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Relevant pieces of previous conversation:\n",
      "input: My favorite musician is Taylor Swift\n",
      "output: I also love Taylor Swift\n",
      "\n",
      "(You do not need to use these pieces of information if not relevant)\n",
      "\n",
      "Current conversation:\n",
      "Human: Who did I say was my favorite musician?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I apologize for the confusion. It seems like you have already mentioned that your favorite musician is Taylor Swift earlier in our conversation, so I will respond with \"Taylor Swift\".'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_with_summary.predict(input=\"Who did I say was my favorite musician?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A totally random sidenote unrelated to this notebook ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell has nothing to do with this notebook ... I just ran it because I wanted to pull down this dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "# This dataset just came available today! January 31, 2024 ... the README.md was updated a minute ago! 4:14pm ... \n",
    "dataset = load_dataset(\"teknium/OpenHermes-2.5\")\n",
    "\n",
    "# ugh 5:01pm I ran this again, and it started downloading all the data again ... the README.md was updated 20 minute ago ... is this why\n",
    "# it's downloading again??? I think it is ... \n",
    "\n",
    "# 30m 22.42\n",
    "# ~/.cache/huggingface/datasets/teknium___open_hermes-2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is another side note that I am looking into ...\n",
    "\n",
    "[nomic-ai/nomic-embed-text-v1](https://huggingface.co/nomic-ai/nomic-embed-text-v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0]\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "sentences = ['What is TSNE?', 'Who is Laurens van der Maaten?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json: 100%|██████████| 28.0/28.0 [00:00<00:00, 247kB/s]\n",
      "config.json: 100%|██████████| 570/570 [00:00<00:00, 4.84MB/s]\n",
      "vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 1.31MB/s]\n",
      "tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 1.25MB/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next cell blew up with the following error message ...\n",
    "\n",
    "ImportError: This modeling file requires the following packages that were not found in your environment: einops. Run `pip install einops`\n",
    "\n",
    "So yeah I installed this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pytorch_model.bin: 100%|██████████| 547M/547M [07:54<00:00, 1.15MB/s] \n",
      "<All keys matched successfully>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pytorch_model.bin:  98%|█████████▊| 535M/547M [07:52<00:10, 1.17MB/s]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NomicBertModel(\n",
       "  (embeddings): NomicBertEmbeddings(\n",
       "    (word_embeddings): Embedding(30528, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "  )\n",
       "  (emb_drop): Dropout(p=0.0, inplace=False)\n",
       "  (emb_ln): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  (encoder): NomicBertEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-11): 12 x NomicBertBlock(\n",
       "        (attn): NomicBertAttention(\n",
       "          (rotary_emb): NomicBertRotaryEmbedding()\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (mlp): NomciBertGatedMLP(\n",
       "          (fc11): Linear(in_features=768, out_features=3072, bias=False)\n",
       "          (fc12): Linear(in_features=768, out_features=3072, bias=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=False)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (norm1): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained('nomic-ai/nomic-embed-text-v1', trust_remote_code=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0091,  0.0410, -0.0110,  ...,  0.0052, -0.0244, -0.0348],\n",
      "        [-0.0032,  0.0080, -0.0255,  ...,  0.0421, -0.0296,  0.0188]])\n"
     ]
    }
   ],
   "source": [
    "embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia Collection Example\n",
    "\n",
    "So now that we have seen a working example of a simple chain, let's look at a more detailed example.\n",
    "\n",
    "Restart the kernel before proceeding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Dataset Download and Inspection\n",
    "\n",
    "Let's start with a pre-built dataset, the [wikipedia](https://huggingface.co/datasets/wikipedia) dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rob/miniforge3/envs/milvus/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'url', 'title', 'text'],\n",
       "    num_rows: 205328\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "wikipediaData = load_dataset(\"wikipedia\", \"20220301.simple\", \n",
    "                             split='train',\n",
    "                             trust_remote_code=True)\n",
    "wikipediaData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "wikipediaDf = pd.DataFrame(wikipediaData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://simple.wikipedia.org/wiki/April</td>\n",
       "      <td>April</td>\n",
       "      <td>April is the fourth month of the year in the J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://simple.wikipedia.org/wiki/August</td>\n",
       "      <td>August</td>\n",
       "      <td>August (Aug.) is the eighth month of the year ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>https://simple.wikipedia.org/wiki/Art</td>\n",
       "      <td>Art</td>\n",
       "      <td>Art is a creative activity that expresses imag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>https://simple.wikipedia.org/wiki/A</td>\n",
       "      <td>A</td>\n",
       "      <td>A or a is the first letter of the English alph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>https://simple.wikipedia.org/wiki/Air</td>\n",
       "      <td>Air</td>\n",
       "      <td>Air refers to the Earth's atmosphere. Air is a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>https://simple.wikipedia.org/wiki/Autonomous%2...</td>\n",
       "      <td>Autonomous communities of Spain</td>\n",
       "      <td>Spain is divided in 17 parts called autonomous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13</td>\n",
       "      <td>https://simple.wikipedia.org/wiki/Alan%20Turing</td>\n",
       "      <td>Alan Turing</td>\n",
       "      <td>Alan Mathison Turing OBE FRS (London, 23 June ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14</td>\n",
       "      <td>https://simple.wikipedia.org/wiki/Alanis%20Mor...</td>\n",
       "      <td>Alanis Morissette</td>\n",
       "      <td>Alanis Nadine Morissette (born June 1, 1974) i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17</td>\n",
       "      <td>https://simple.wikipedia.org/wiki/Adobe%20Illu...</td>\n",
       "      <td>Adobe Illustrator</td>\n",
       "      <td>Adobe Illustrator is a computer program for ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18</td>\n",
       "      <td>https://simple.wikipedia.org/wiki/Andouille</td>\n",
       "      <td>Andouille</td>\n",
       "      <td>Andouille is a type of pork sausage. It is spi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                                url  \\\n",
       "0   1            https://simple.wikipedia.org/wiki/April   \n",
       "1   2           https://simple.wikipedia.org/wiki/August   \n",
       "2   6              https://simple.wikipedia.org/wiki/Art   \n",
       "3   8                https://simple.wikipedia.org/wiki/A   \n",
       "4   9              https://simple.wikipedia.org/wiki/Air   \n",
       "5  12  https://simple.wikipedia.org/wiki/Autonomous%2...   \n",
       "6  13    https://simple.wikipedia.org/wiki/Alan%20Turing   \n",
       "7  14  https://simple.wikipedia.org/wiki/Alanis%20Mor...   \n",
       "8  17  https://simple.wikipedia.org/wiki/Adobe%20Illu...   \n",
       "9  18        https://simple.wikipedia.org/wiki/Andouille   \n",
       "\n",
       "                             title  \\\n",
       "0                            April   \n",
       "1                           August   \n",
       "2                              Art   \n",
       "3                                A   \n",
       "4                              Air   \n",
       "5  Autonomous communities of Spain   \n",
       "6                      Alan Turing   \n",
       "7                Alanis Morissette   \n",
       "8                Adobe Illustrator   \n",
       "9                        Andouille   \n",
       "\n",
       "                                                text  \n",
       "0  April is the fourth month of the year in the J...  \n",
       "1  August (Aug.) is the eighth month of the year ...  \n",
       "2  Art is a creative activity that expresses imag...  \n",
       "3  A or a is the first letter of the English alph...  \n",
       "4  Air refers to the Earth's atmosphere. Air is a...  \n",
       "5  Spain is divided in 17 parts called autonomous...  \n",
       "6  Alan Mathison Turing OBE FRS (London, 23 June ...  \n",
       "7  Alanis Nadine Morissette (born June 1, 1974) i...  \n",
       "8  Adobe Illustrator is a computer program for ma...  \n",
       "9  Andouille is a type of pork sausage. It is spi...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikipediaDf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 205328 entries, 0 to 205327\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   id      205328 non-null  object\n",
      " 1   url     205328 non-null  object\n",
      " 2   title   205328 non-null  object\n",
      " 3   text    205328 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 6.3+ MB\n"
     ]
    }
   ],
   "source": [
    "wikipediaDf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking above it's obvious the only field we really care about is the text field. So let's fire this into Milvus, shall we ...!\n",
    "\n",
    "We probably want to know some facts about the data in the text field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum width of the id column: 6\n",
      "Maximum width of the url column: 214\n",
      "Maximum width of the title column: 118\n",
      "Maximum width of the text column: 236695\n"
     ]
    }
   ],
   "source": [
    "# Calculate minimum and maximum string lengths in the column\n",
    "max_width_id = wikipediaDf['id'].str.len().max()\n",
    "max_width_url = wikipediaDf['url'].str.len().max()\n",
    "max_width_title = wikipediaDf['title'].str.len().max()\n",
    "max_width_text = wikipediaDf['text'].str.len().max()\n",
    "\n",
    "# Print the results\n",
    "print(f\"Maximum width of the id column: {max_width_id}\")\n",
    "print(f\"Maximum width of the url column: {max_width_url}\")\n",
    "print(f\"Maximum width of the title column: {max_width_title}\")\n",
    "print(f\"Maximum width of the text column: {max_width_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to do some simple clean up of the data. Specifically, we want to reduce the width of the text column to the maximum width allowable with a VARCHAR field in Milvus, which is 65,535 characters.\n",
    "\n",
    "This failed to import all of the data, so I adjusted the trim width to (TEXT_MAX_WIDTH - 16), but it too failed on the import. So I went more agressive and trimmed it to (TEXT_MAX_WIDTH - 8192) and now all of the data is imported! We have 205328 records after import!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_MAX_WIDTH = 65535\n",
    "\n",
    "def truncate_text(text):\n",
    "    # we will only grab the first (65535-16) characters from the text field.   FAIL\n",
    "    # we will only grab the first (65535-8192) characters from the text field. SUCCESS\n",
    "    return text[0:TEXT_MAX_WIDTH - 8192]\n",
    "\n",
    "wikipediaDf['text'] = wikipediaDf['text'].apply(truncate_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57343"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikipediaDf['text'].str.len().max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I guess the first thing I want to just try is inject some of this data into a Milvus collection. \n",
    "\n",
    "I am referencing [this](https://milvus.io/docs/example_code.md) as my example.\n",
    "\n",
    "[Create a Collection](https://milvus.io/docs/create_collection.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inject all columns from the a limited number of rows of the data into a new Milvus collection.\n",
    "\n",
    "First we need to define the schema of our collection.\n",
    "\n",
    "Let's also determine the min and max widths of the other string columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Milvus Collection Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, establish a connection to the milvus db.\n",
    "\n",
    "[Manage Databases](https://milvus.io/docs/manage_databases.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import (\n",
    "    connections,\n",
    "    utility,\n",
    "    FieldSchema, CollectionSchema, DataType,\n",
    "    Collection,\n",
    "    db\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = connections.connect(host=\"127.0.0.1\", port=19530)\n",
    "\n",
    "DBNAME = \"WikipediaDatabase\"\n",
    "COLLECTION_NAME = \"WikipediaCollection\"\n",
    "\n",
    "FIELD_2_EMBED = 'text'\n",
    "EMBEDDING_FIELD = \"embedding\"\n",
    "\n",
    "DIMENSION = 768 # the size of our embedding vector and it depends on the embedding model. We will use \"sentence-transformers/all-mpnet-base-v2\".\n",
    "BATCH_SIZE = 128\n",
    "TOPK = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'v2.3.7'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utility.get_server_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  you can only run this once ... so be careful ... \n",
    "db.create_database(DBNAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to tell Milvus which database you want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.using_database(DBNAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if utility.has_collection(COLLECTION_NAME):\n",
    "    # you can run this multiple times, and no errors will come back\n",
    "    utility.drop_collection(COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, define the schema for our new collection and add it to the db."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://milvus.io/docs/create_collection.md\n",
    "\n",
    "from pymilvus import CollectionSchema, FieldSchema, DataType\n",
    "\n",
    "pk = FieldSchema(\n",
    "  name=\"pk\",\n",
    "  dtype=DataType.INT64,\n",
    "  is_primary=True,\n",
    "  auto_id = True\n",
    ")\n",
    "\n",
    "id = FieldSchema(\n",
    "  name=\"id\",\n",
    "  dtype=DataType.INT32,\n",
    "  # The default value will be used if this field is left empty during data inserts or upserts.\n",
    "  # The data type of `default_value` must be the same as that specified in `dtype`.\n",
    "  default_value=-1\n",
    ")\n",
    "\n",
    "url = FieldSchema(\n",
    "  name=\"url\",\n",
    "  dtype=DataType.VARCHAR,\n",
    "  # max_length=(max_width_url + 2),\n",
    "  max_length=256,\n",
    "  # The default value will be used if this field is left empty during data inserts or upserts.\n",
    "  # The data type of `default_value` must be the same as that specified in `dtype`.\n",
    "  default_value=\"Unknown url\"\n",
    ")\n",
    "\n",
    "title = FieldSchema(\n",
    "  name=\"title\",\n",
    "  dtype=DataType.VARCHAR,\n",
    "  # max_length=(max_width_title + 2),\n",
    "  max_length=256, \n",
    "  # The default value will be used if this field is left empty during data inserts or upserts.\n",
    "  # The data type of `default_value` must be the same as that specified in `dtype`.\n",
    "  default_value=\"Unknown title\"\n",
    ")\n",
    "\n",
    "text = FieldSchema(\n",
    "  name=FIELD_2_EMBED,\n",
    "  dtype=DataType.VARCHAR,\n",
    "  # max_length=(max_width_text + 2), # turns out, we can't do this ... 65535 is the max width for a VARCHAR field\n",
    "  max_length=TEXT_MAX_WIDTH,\n",
    "  # The default value will be used if this field is left empty during data inserts or upserts.\n",
    "  # The data type of `default_value` must be the same as that specified in `dtype`.\n",
    "  default_value=\"Unknown text\"\n",
    ")\n",
    "\n",
    "# Wow! Really! We NEED to have a vector field!\n",
    "# SchemaNotReadyException: <SchemaNotReadyException: (code=1, message=No vector field is found.)>\n",
    "text_vector = FieldSchema(\n",
    "  name=EMBEDDING_FIELD,\n",
    "  dtype=DataType.FLOAT_VECTOR,\n",
    "  dim=DIMENSION\n",
    ")\n",
    "\n",
    "schema = CollectionSchema(\n",
    "  fields=[pk, id, url, title, text, text_vector],\n",
    "  description=\"Wikipedia Articles\",\n",
    "  enable_dynamic_field=True\n",
    ")\n",
    "\n",
    "# collection_name = \"wikipedia\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a collection with the schema defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import Collection\n",
    "\n",
    "collection = Collection(\n",
    "    name=COLLECTION_NAME,\n",
    "    schema=schema,\n",
    "    using='default',\n",
    "    shards_num=2\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! The collection get's created into the Wikipedia database. Now let's move onto injecting data into this collection.\n",
    "\n",
    "Hmmm Whelp after rebooting, spinning stuff back up, then using Attu to whack the Wikipedia database, I reran the \"Wikipedia Collection Example\" code and can now see a 'wikipedia' collection in the 'default' database, and there is no 'Wikipedia' database ... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next thing we need to do is define the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_params = {\n",
    "  \"metric_type\":\"L2\",\n",
    "  \"index_type\":\"IVF_FLAT\",\n",
    "  \"params\":{\"nlist\":1024}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.create_index(field_name=EMBEDDING_FIELD, index_params=index_params)\n",
    "collection.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Add data to the Collection \n",
    "\n",
    "[Insert data to Milvus](https://milvus.io/docs/insert_data.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to create out embeddings. We will be using the `SentenceTransformer` library to create our embeddings.\n",
    "\n",
    "[sentence-transformers/all-mpnet-base-v2](https://huggingface.co/sentence-transformers/all-mpnet-base-v2)\n",
    "\n",
    "This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# This is their best model ...\n",
    "sentenceTransformer = SentenceTransformer('all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_insert(data):\n",
    "\n",
    "    text = data[3]\n",
    "\n",
    "    embeddings = sentenceTransformer.encode(text)\n",
    "\n",
    "    insert = [data[0], data[1], data[2], text, [x for x in embeddings]]\n",
    "\n",
    "    collection.insert(insert)\n",
    "\n",
    "                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = Collection(COLLECTION_NAME, using=DBNAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52min 56s, sys: 1min 21s, total: 54min 17s\n",
      "Wall time: 8min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data_batch = [[],[],[],[]]\n",
    "\n",
    "for id, url, title, text in zip(wikipediaDf.loc[:, \"id\"], wikipediaDf.loc[:, \"url\"], wikipediaDf.loc[:, \"title\"], wikipediaDf.loc[:, \"text\"]):\n",
    "    \n",
    "    data_batch[0].append(int(id)) # this needs to be an integer, not a string \n",
    "    data_batch[1].append(url)\n",
    "    data_batch[2].append(title)\n",
    "    data_batch[3].append(text) \n",
    "    \n",
    "\n",
    "    if len(data_batch[0]) % BATCH_SIZE == 0:\n",
    "        embed_insert(data_batch)\n",
    "        data_batch = [[],[],[],[]]\n",
    "\n",
    "# final insert if we still have some data left\n",
    "if len(data_batch[0]) != 0:\n",
    "    embed_insert(data_batch)\n",
    "\n",
    "# 7m 57.6s\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_terms = ['What is Alan Turing famous for?',\n",
    "                'Who is Alanis Morissette?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_search(search_term):\n",
    "    embeddings = sentenceTransformer.encode(search_term)\n",
    "    return [x for x in embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_data = embed_search(search_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "startTime = time.time()\n",
    "results = collection.search(\n",
    "    data=search_data,\n",
    "    anns_field=EMBEDDING_FIELD,\n",
    "    param={\"metric_type\": \"L2\", \"params\": {\"nprobe\": 10}},\n",
    "    limit=TOPK,\n",
    "    output_fields=[FIELD_2_EMBED],\n",
    ")\n",
    "endTime = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Term:  What is Alan Turing famous for?\n",
      "Results: \n",
      "Alan Mathison Turing OBE FRS (London, 23 June 1912 – Wilmslow, Cheshire, 7 June 1954) was an English mathematician and computer scientist. He was born in Maida Vale, London.\n",
      "\n",
      "Early life and family \n",
      "Alan Turing was born in Maida Vale, London on 23 June 1912. His father was part of a family of merchants from Scotland. His mother, Ethel Sara, was the daughter of an engineer.\n",
      "\n",
      "Education \n",
      "Turing went to St. Michael's, a school at 20 Charles Road, St Leonards-on-sea, when he was five years old.\n",
      "\"This is only a foretaste of what is to come, and only the shadow of what is going to be.” – Alan Turing.\n",
      "\n",
      "The Stoney family were once prominent landlords, here in North Tipperary. His mother Ethel Sara Stoney (1881–1976) was daughter of Edward Waller Stoney (Borrisokane, North Tipperary) and Sarah Crawford (Cartron Abbey, Co. Longford); Protestant Anglo-Irish gentry.\n",
      "\n",
      "Educated in Dublin at Alexandra School and College; on October 1st 1907 she married Julius Mathison Turing, latter son of Reverend John Robert Turing and Fanny Boyd, in Dublin. Born on June 23rd 1912, Alan Turing would go on to be regarded as one of the greatest figures of the twentieth century.\n",
      "\n",
      "A brilliant mathematician and cryptographer Alan was to become the founder of modern-day computer science and artificial intelligence; designing a machine at Bletchley Park to break secret Enigma encrypted messages used by the Nazi German war machine to protect sensitive commercial, diplomatic and military communications during World War 2. Thus, Turing made the single biggest contribution to the Allied victory in the war against Nazi Germany, possibly saving the lives of an estimated 2 million people, through his effort in shortening World War II.\n",
      "\n",
      "In 2013, almost 60 years later, Turing received a posthumous Royal Pardon from Queen Elizabeth II. Today, the “Turing law” grants an automatic pardon to men who died before the law came into force, making it possible for living convicted gay men to seek pardons for offences now no longer on the statute book.\n",
      "\n",
      "Alas, Turing accidentally or otherwise lost his life in 1954, having been subjected by a British court to chemical castration, thus avoiding a custodial sentence. He is known to have ended his life at the age of 41 years, by eating an apple laced with cyanide.\n",
      "\n",
      "Career \n",
      "Turing was one of the people who worked on the first computers. He created the theoretical  Turing machine in 1936. The machine was imaginary, but it included the idea of a computer program.\n",
      "\n",
      "Turing was interested in artificial intelligence. He proposed the Turing test, to say when a machine could be called \"intelligent\". A computer could be said to \"think\" if a human talking with it could not tell it was a machine.\n",
      "\n",
      "During World War II, Turing worked with others to break German ciphers (secret messages). He  worked for the Government Code and Cypher School (GC&CS) at Bletchley Park, Britain's codebreaking centre that produced Ultra intelligence.\n",
      "Using cryptanalysis, he helped to break the codes of the Enigma machine. After that, he worked on other German codes.\n",
      "\n",
      "From 1945 to 1947, Turing worked on the design of the ACE (Automatic Computing Engine) at the National Physical Laboratory. He presented a paper on 19 February 1946. That paper was \"the first detailed design of a stored-program computer\". Although it was possible to build ACE, there were delays in starting the project. In late 1947 he returned to Cambridge for a sabbatical year. While he was at Cambridge, the Pilot ACE was built without him. It ran its first program on 10 May 1950.\n",
      "\n",
      "Private life \n",
      "Turing was a homosexual man. In 1952, he admitted having had sex with a man in England. At that time, homosexual acts were illegal. Turing was convicted. He had to choose between going to jail and taking hormones to lower his sex drive. He decided to take the hormones. After his punishment, he became impotent. He also grew breasts.\n",
      "\n",
      "In May 2012, a private member's bill was put before the House of Lords to grant Turing a statutory pardon. In July 2013, the government supported it. A royal pardon was granted on 24 December 2013.\n",
      "\n",
      "Death \n",
      "In 1954, Turing died from cyanide poisoning. The cyanide came from either an apple which was poisoned with cyanide, or from water that had cyanide in it. The reason for the confusion is that the police never tested the apple for cyanide. It is also suspected that he committed suicide.\n",
      "\n",
      "The treatment forced on him is now believed to be very wrong. It is against medical ethics and international laws of human rights. In August 2009, a petition asking the British Government to apologise to Turing for punishing him for being a homosexual was started. The petition received thousands of signatures. Prime Minister Gordon Brown acknowledged the petition. He called Turing's treatment \"appalling\".\n",
      "\n",
      "References\n",
      "\n",
      "Other websites \n",
      "Jack Copeland 2012. Alan Turing: The codebreaker who saved 'millions of lives'. BBC News / Technology \n",
      "\n",
      "English computer scientists\n",
      "English LGBT people\n",
      "English mathematicians\n",
      "Gay men\n",
      "LGBT scientists\n",
      "Scientists from London\n",
      "Suicides by poison\n",
      "Suicides in the United Kingdom\n",
      "1912 births\n",
      "1954 deaths\n",
      "Officers of the Order of the British Empire  ----  0.6069707870483398\n",
      "Niklaus Emil Wirth (born 15 February 1934) is a Swiss computer scientist. He is best known for designing several programming languages, including Pascal, and for pioneering several classic topics in software engineering. In 1984 he won the Turing Award, generally recognized as the highest distinction in computer science, for developing a sequence of innovative computer languages.\n",
      "\n",
      "References\n",
      "\n",
      "Turing Award winners\n",
      "1934 births\n",
      "Living people\n",
      "Swiss scientists\n",
      "Computer scientists\n",
      "People from Winterthur  ----  0.6617353558540344\n",
      "Alfred Vaino Aho (born August 9, 1941) is a Canadian computer scientist. He is best known for his work on programming languages, compilers, and related algorithms. He has written many textbooks on the art and science of computer programming. He and his long-time partner Jeffrey Ullman are the recipients of the 2020 Turing Award.\n",
      "\n",
      "References\n",
      "\n",
      "1941 births\n",
      "Living people\n",
      "Turing Award winners\n",
      "Canadian computer scientists\n",
      "Writers from Ontario  ----  0.6874799728393555\n",
      "Conway Maurice Berners-Lee (19 September 1921 – 1 February 2019) was an English mathematician and computer scientist.\n",
      "\n",
      "He worked as a member of the team that developed the Ferranti Mark 1, the world's first commercial stored program electronic computer.\n",
      "\n",
      "He was born in Birmingham in 1921 and was the father of Sir Tim Berners-Lee, the inventor of the World Wide Web.\n",
      "\n",
      "He retired in 1986 and died on 1 February 2019 at the age of 97.\n",
      "\n",
      "References\n",
      "\n",
      "Other websites\n",
      " The National Archives: The Ferranti Collection including:\n",
      " Linear Programming \"Arrives\" By Dr. D.G. Prinz & Mr C.M Berners-Lee of Ferranti Ltd. (Paper)  1996.10/6/12/28/10  1957\n",
      " The Use of Electronic Computers in the Chemical Industry. By C.M. Berners-Lee  1996.10/6/12/28/28  1959\n",
      " The Use of Computers for Optimal Planning. By C.M. Berners-Lee  1996.10/6/12/28/29  1959\n",
      " Photograph with colleagues (under Ferranti and ICL)\n",
      " An interview with Conway Berners-Lee from the British Library http://www.bl.uk/voices-of-science/interviewees/conway-berners-lee\n",
      "\n",
      "1921 births\n",
      "2019 deaths\n",
      "English mathematicians\n",
      "English computer scientists\n",
      "People from Birmingham  ----  0.7740890979766846\n",
      "Frederick Phillips Brooks, Jr. (born April 19, 1931) is an American computer architect,  software engineer, and computer scientist.\n",
      "\n",
      "He is best known for managing the development of IBM's System/360 family of computers alongside Gerrit Blaauw and Gene Amdahl and the OS/360 software support package, then later writing candidly about the process in his seminal book The Mythical Man-Month.  Brooks has received many awards, including the National Medal of Technology in 1985 and the Turing Award in 1999.\n",
      "\n",
      "Brooks was born in Durham, North Carolina. He studied Duke University, graduating in 1953 with a Bachelor of Science degree in Physics, and he received a Ph.D. in Applied Mathematics (Computer Science) from Harvard University in 1956, supervised by Howard Aiken.\n",
      "\n",
      "References\n",
      "\n",
      "Other websites\n",
      "\n",
      "Turing Award winners\n",
      "1931 births\n",
      "Living people\n",
      "Scientists from North Carolina\n",
      "American computer scientists\n",
      "People from Durham, North Carolina  ----  0.8185070753097534\n",
      "John von Neumann (December 28. 1903 – February 8. 1957) was a Hungarian-American mathematician and physicist.\n",
      "\n",
      "He contributed to many fields, including:\n",
      "\n",
      "Set theory\n",
      "Functional analysis\n",
      "Quantum mechanics\n",
      "Ergodic theory\n",
      "Continuous geometry\n",
      "Economics\n",
      "Game theory\n",
      "Computer science\n",
      "Numerical analysis\n",
      "Systems theory\n",
      "Atatistics\n",
      "\n",
      "He is generally regarded as a prodigy, polymath and one of the most important mathematicians of the 20th century.\n",
      "\n",
      "He was a member of a group called the 'Martians'. They were Hungarian immigrants to the US of extraordinary intellect. Others people in this group were Edward Teller, Paul Erdős, Leó Szilárd and Eugene Wigner.\n",
      "\n",
      "Noteworthy work \n",
      "His textbook on quantum mechanics is one of the first on this topic.\n",
      "His game theory is considered one of the most important tools in competitive strategic management and is also of high importance in biosciences.\n",
      "He is the designer of the Von-Neumann architecture, which is basic to nearly all computers today.\n",
      "He was one of the first proponents of artificial intelligence. He proposed the idea of self replicating machines.  This is why a machine that can replicate itself is now commonly referred to as a 'Von Neumann machine'.\n",
      "With Stanislav Ulam, he did some of the most important calculations in the Manhattan project.\n",
      "He worked at the Institute of Advanced Studies the same time as Albert Einstein, Kurt Gödel and Robert Oppenheimer\n",
      "Well known by computer scientists\n",
      "Principles are included in every modern computer, tablet or phone.\n",
      "\n",
      "References \n",
      "\n",
      "1903 births\n",
      "1957 deaths\n",
      "American mathematicians\n",
      "American physicists\n",
      "Cancer deaths in the United States\n",
      "Disease-related deaths in Washington, D.C.\n",
      "Hungarian mathematicians\n",
      "People from Budapest\n",
      "Systems scientists\n",
      "Hungarian physicists  ----  0.8534125089645386\n",
      "Richard Manning Karp (born January 3, 1935) is an American computer scientist and computational theorist at the University of California, Berkeley. He is known for his research in the theory of algorithms, for which he received a Turing Award in 1985, The Benjamin Franklin Medal in Computer and Cognitive Science in 2004,  and the Kyoto Prize in 2008. \n",
      "\n",
      "He work includes solving problems of combinatorial optimization (mostly network flow), asking questions about what an efficient algorithm looks like, and works about algorithmic complexity theory,.\n",
      "\n",
      "References\n",
      "\n",
      "Other websites\n",
      "\n",
      " ACM Crossroads magazine interview/bio of Richard Karp \n",
      " Karp's Home Page at Berkeley\n",
      "\n",
      "Turing Award winners\n",
      "1935 births\n",
      "American computer scientists\n",
      "Scientists from Boston, Massachusetts\n",
      "\n",
      "Living people  ----  0.8719722032546997\n",
      "Marvin Lee Minsky (August 9, 1927 – January 24, 2016) was an American cognitive scientist in the field of artificial intelligence (AI). He was the co-founder of the Massachusetts Institute of Technology's AI laboratory, and author of several texts on AI and philosophy. He won the Turing Award in 1969.\n",
      "\n",
      "Minskey was born in New York City, New York. He studied at Phillips Academy, Harvard University and at Princeton University. Minskey died in Boston, Massachusetts of a cerebral hemorrhage on January 24, 2016 at the age of 88. His body is chronologically frozen in Scottsdale, Arizona.\n",
      "\n",
      "References\n",
      "\n",
      "Other websites\n",
      "\n",
      " \n",
      " Oral history interview with Terry Winograd at Charles Babbage Institute, University of Minnesota, Minneapolis.  Winograd describes his work in computer science, linguistics, and artificial intelligence at the Massachusetts Institute of Technology (MIT), discussing the work of Marvin Minsky and others.\n",
      " Scientist on the Set: An Interview with Marvin Minsky \n",
      " Marvin Minsky Playlist Appearance on WMBR's Dinnertime Sampler  radio show November 26, 2003\n",
      " Consciousness Is A Big Suitcase: A talk with Marvin Minsky\n",
      " Video of Minsky speaking at the International Conference on Complex Systems, hosted by the New England Complex Systems Institute (NECSI) \n",
      "\n",
      "Turing Award winners\n",
      "1927 births\n",
      "2016 deaths\n",
      "Cryonically preserved people\n",
      "Deaths from cerebral hemorrhage\n",
      "American computer scientists\n",
      "Scientists from New York City  ----  0.8910467624664307\n",
      "Frances Elizabeth \"Fran\" Allen (August 4, 1932 – August 4, 2020) was an American computer scientist and pioneer in the field of optimizing compilers. Her achievements include seminal work in compilers, code optimization, and parallelization. She also had a role in intelligence work on programming languages and security codes for the National Security Agency.\n",
      "\n",
      "Allen was the first female IBM Fellow and in 2006 became the first woman to win the Turing Award.\n",
      "\n",
      "Allen died on her 88th birthday on August 4, 2020 in Schenectady, New York from Alzheimer's disease-related problems.\n",
      "\n",
      "References\n",
      "\n",
      "Other websites\n",
      "\n",
      "Frances Allen via IBM Women in WITI Hall of Fame.\n",
      "Frances Allen: 2000 Fellow Awards Recipient via Computer History Museum\n",
      "Fran Allen on Compilers and Parallel Computing Systems Notes from her 2008 Organick Memorial Lecture\n",
      "\n",
      "Turing Award winners\n",
      "1932 births\n",
      "2020 deaths\n",
      "Deaths from Alzheimer's disease\n",
      "Disease-related deaths in New York\n",
      "American computer scientists\n",
      "Scientists from New York  ----  0.892339825630188\n",
      "Roger D. Moore (November 16, 1939 – March 21, 2019) was an American computer scientist. He worked in the design and implementation of APL.\n",
      "\n",
      "Moore was a cofounder of I. P. Sharp Associates and held a senior position in the company for many years. Before this, he worked at Stanford University and wrote the ALGOL 60 compiler for the Ferranti-Packard 6000 and the ICT 1900.\n",
      "\n",
      "References\n",
      "\n",
      "1939 births\n",
      "2019 deaths\n",
      "American computer scientists\n",
      "Scientists from California  ----  0.897541880607605\n",
      "Search Term:  Who is Alanis Morissette?\n",
      "Results: \n",
      "Alanis Nadine Morissette (born June 1, 1974) is a Grammy Award-winning Canadian-American singer and songwriter. She was born in Ottawa, Canada. She began singing in Canada as a teenager in 1990. In 1995, she became popular all over the world.\n",
      "\n",
      "As a young child in Canada, Morissette began to act on television, including 5 episodes of the long-running series, You Can't Do That on Television. Her first album was released only in Canada in 1990.\n",
      "\n",
      "Her first international album was Jagged Little Pill, released in 1995. It was a rock-influenced album. Jagged has sold more than 33 million units globally. It became the best-selling debut album in music history. Her next album, Supposed Former Infatuation Junkie, was released in 1998. It was a success as well. Morissette took up producing duties for her next albums, which include Under Rug Swept, So-Called Chaos and Flavors of Entanglement. Morissette has sold more than 60 million albums worldwide.\n",
      "\n",
      "She also acted in several movies, including Kevin Smith's Dogma, where she played God.\n",
      "\n",
      "About her life\n",
      "Alanis Morissette was born in Riverside Hospital of Ottawa in Ottawa, Ontario. Her father is French-Canadian. Her mother is from Hungary. She has an older brother, Chad, and a twin brother, Wade, who is 12 minutes younger than she is. Her parents had worked as teachers at a military base in Lahr, Germany.\n",
      "\n",
      "Morissette became an American citizen in 2005. She is still Canadian citizen.\n",
      "\n",
      "On May 22, 2010, Morissette married rapper Mario \"MC Souleye\" Treadway.\n",
      "\n",
      "Jagged Little Pill\n",
      "Morissette has had many albums. Her 1995 album Jagged Little Pill became a very popular album. It has sold over 30 million copies worldwide. The album caused Morissette to win four Grammy Awards. The album Jagged Little Pill touched many people.\n",
      "\n",
      "On the album, Morissette sang songs about many different things. These things include:\n",
      "love (in the song \"Head Over Feet\")\n",
      "life (in the songs \"Ironic\" and \"You Learn\")\n",
      "her feelings (in the songs \"Hand In My Pocket\" and \"All I Really Want\")\n",
      "sadness (in the song \"Mary Jane\")\n",
      "anger (in the song \"You Oughta Know\")\n",
      "frustration (in the songs \"Not the Doctor\" and \"Wake Up\")\n",
      "\n",
      "Discography\n",
      "\n",
      "Albums\n",
      "Alanis (Canada-only, 1991)\n",
      "Now Is the Time (Canada-only, 1992)\n",
      "Jagged Little Pill (1995)\n",
      "Supposed Former Infatuation Junkie (1998)\n",
      "Alanis Unplugged (1999)\n",
      "Under Rug Swept (2002)\n",
      "Feast on Scraps (CD/DVD, 2002)\n",
      "So-Called Chaos (2004)\n",
      "Jagged Little Pill Acoustic (2005)\n",
      "Alanis Morissette: The Collection (2005)\n",
      "Flavors of Entanglement (2008)\n",
      "Havoc and Bright Lights (2012)\n",
      "\n",
      "Selected songs\n",
      "Morissette has written many songs. Some of her most famous songs are:\n",
      "\"You Oughta Know\" - This song is to Morissette's ex-boyfriend, a man she once loved. In this song, Morissette is very angry. She wants her ex-boyfriend to know that he caused many problems after leaving her for another woman.\n",
      "\"Ironic\" - This song is about life. It contains several stories about unlucky people. In one of the stories, a man is afraid of flying on airplanes. He finally flies in one, but the airplane crashes.\n",
      "\"You Learn\" - In this song, Morissette says that bad things happen in life, but people learn from them. Anyone can make bad things into good things. She wants people to try new things in life.\n",
      "\"Uninvited\" - In this song, Morissette is not happy because she is famous. She does not know whether she wants to continue to be famous or not.\n",
      "\"Thank U\" - In this song, she thanks many things that have helped her. She thanks India, a country she visited and almost died in. She also lists ways she can improve herself.\n",
      "\"Hands Clean\" - In this song, a man does something bad, and tells Morissette not to tell anyone else the bad thing the man did. She hides the man's secret for many years.\n",
      "\n",
      "References\n",
      "\n",
      "Other websites \n",
      "\n",
      " Official website\n",
      "\n",
      "1974 births\n",
      "Living people\n",
      " \n",
      "American child actors\n",
      "American movie actors\n",
      "American pop musicians\n",
      "American rock singers\n",
      "American singer-songwriters\n",
      "American television actors\n",
      "Canadian movie actors\n",
      "Canadian pop singers\n",
      "Canadian rock singers\n",
      "Canadian singer-songwriters\n",
      "Canadian television actors\n",
      "Grammy Award winners\n",
      "People from Ottawa\n",
      "Singers from Ontario\n",
      "Twin people from Canada  ----  0.7127950191497803\n",
      "Ingrid Ellen Michaelson (born December 8, 1979, New York City) is an American musician. She has had five studio albums since 2005. She has not been signed to any major record labels. Her music has been used in several television programs, including The Vampire Diaries and Scrubs. Michaelson performed with singer Sara Bareilles on the hit single Winter Song.\n",
      "\n",
      "Singers from New York\n",
      "1979 births\n",
      "Living people  ----  0.904710054397583\n",
      "Janis Ian (born Janis Eddy Fink, April 7, 1951) is an American songwriter, singer, musician, columnist, and science fiction writer.  She stated singing folk in the mid-sixties while she was still a teenager.  She sang the most in the 1960s and the 1970s, but she's still singing today. In 1975, Ian won a Grammy Award for her song, \"At Seventeen\".\n",
      "\n",
      "Ian is openly lesbian and is married to a woman.\n",
      "\n",
      "Discography\n",
      "\n",
      "Albums\n",
      " Janis Ian (1967) #29 US (Verve) / (1978) (Columbia) / (Bonus Track) (2004) (Festival, Cooking Vinyl UK)\n",
      " For All the Seasons of Your Mind (1967) #179 US (Verve)\n",
      " The Secret Life of J. Eddy Fink (1968) (Verve)\n",
      " Who Really Cares (1969) (Verve)\n",
      " Present Company (1971) #223 US (Capitol)\n",
      " Stars (1974) #83 US, #63 (Columbia) / (Bonus Track) (2004) (Festival, Cooking Vinyl)\n",
      " Between the Lines (1975) #1 US, #22 Japan (Columbia, Festival) / (Bonus Track) (2004) (Festival, Cooking Vinyl UK)\n",
      " Aftertones (1976) #12 US, #1 Japan (Columbia) / (Bonus Track) (2004) (Festival, Cooking Vinyl UK)\n",
      " Miracle Row (1977) #45 US, #26 Japan (Columbia) /  (Bonus Track) (2004) (Festival, Cooking Vinyl UK)\n",
      " Night Rains (1979) (Columbia)\n",
      " Restless Eyes (1981) #156 US (Columbia)\n",
      " Uncle Wonderful (1983) (Festival) (Australia only)\n",
      " Breaking Silence (1993) (Morgan Creek) / (Bonus Track) (2003) (Festival, Cooking Vinyl UK)\n",
      " Simon Renshaw Presents: Janis Ian Shares Your Pain (1995) (not released until 12.09)\n",
      " Revenge (1995) (Beacon)\n",
      " Hunger (1997) (Windham Hill)\n",
      " god & the fbi (2000) (Windham Hill) / (3 Bonus Tracks) (2000) (JVC Japan)\n",
      " Lost Cuts 1 (2001) (Rude Girl)\n",
      " Billie's Bones (2004) (Oh Boy, Rude Girl Cooking Vinyl US)s Night Rains (Bonus Track) (2004) (Festival, Cooking Vinyl UK)\n",
      " Billie's Bones (Bonus Track) (2004) (JVC Japan)\n",
      " Folk is the New Black (2006) (Rude Girl) / (With DVD) (2006) (Evasound)\n",
      " Revenge (Bonus Track) (2006) (Cooking Vinyl UK 2003) (WEA)\n",
      "\n",
      "Compilation albums\n",
      " Remember (1978) (JVC Japan)\n",
      " The Best of Janis Ian (1980) (CBS)\n",
      " My Favourites (1980) (CBS)\n",
      " Stars/Night Rains (Double Album) (1987) (CBS)\n",
      " At Seventeen (1990) (CBS)\n",
      " Up 'Til Now (1992) (Sony)\n",
      " Society's Child: The Verve Recordings (1995) (Polydor)\n",
      " Live on the Test 1976 (1995) (BBC World Wide)\n",
      " Unreleased 1: Mary's Eyes (1998) (Rude Girl)\n",
      " The Bottom Line Encore Collection (1999) (Velvet)\n",
      " The Best of Janis Ian (2002) (Festival)\n",
      " Live: Working Without a Net (2003) (Rude Girl)\n",
      " Souvenirs: Best of 1972-1981 (US CD) (2004) (Rude Girl) / (Japan CD) (2004) (JVC Japan) / (CD/DVD) (2006) (Evasound)\n",
      " Unreleased 2: Take No Prisoners (2006) (Rude Girl)\n",
      " Unreleased 3: Society's Child (2006) (Rude Girl)\n",
      " Ultimate Best (2007) (JVC Victory)\n",
      " Best of Janis Ian: Autobiography Collection (2008) (Rude Girl)\n",
      " The Essential Janis Ian (2009)\n",
      "\n",
      "Singles\n",
      "\n",
      "DVDs\n",
      " Live at Club Cafe (2005) (Rude Girl)\n",
      " Janismania (2005) (Rude Girl)\n",
      " Through the Years: A Retrospective (2007) (Rude Girl)\n",
      " Janis Ian '79: Live in Japan & Australia'' (2008) (Rude Girl)\n",
      "\n",
      "References\n",
      "\n",
      "Other websites \n",
      " Official website\n",
      " Janis Ian's Pearl Foundation\n",
      " \n",
      " Janis Ian interview on Slashdot\n",
      " 2006 interview\n",
      " Janis Ian archive on NPR Music\n",
      "\n",
      "1951 births\n",
      "Living people\n",
      "American composers\n",
      "American folk musicians\n",
      "American guitarists\n",
      "American science fiction writers\n",
      "Grammy Award winners\n",
      "Jewish American writers\n",
      "Lesbians\n",
      "LGBT novelists\n",
      "LGBT people from New York City\n",
      "LGBT singers\n",
      "LGBT songwriters\n",
      "Musicians from New York City\n",
      "Singers from New York City\n",
      "Writers from New York City  ----  0.9103835821151733\n",
      "Allison Iraheta (born April 27, 1992) is an American musician who was fourth place in the eighth season for American Idol. Her first album Just Like You was released in December 2009. She also performs cover songs. Allison was born in Los Angeles.\n",
      "\n",
      "References\n",
      "\n",
      "Singers from Los Angeles\n",
      "American pop musicians\n",
      "1992 births\n",
      "Living people  ----  0.9530930519104004\n",
      "Camille Dalmais (born 1978, Paris, France) is a French singer. She is famous in France. Her first album was made in 2002.\n",
      "\n",
      "References\n",
      "\n",
      "1978 births\n",
      "Living people\n",
      "French singers  ----  0.9561903476715088\n",
      "Aimee Mann (September 8 1960, Richmond, Virginia) is an American singer-songwriter. She has teamed up with many pop rock bands. She is known for singing with the group 'Til Tuesday in the 1980s, with many hit songs.\n",
      "\n",
      "Mann married musician Michael Penn in 1997.\n",
      "\n",
      "American singer-songwriters\n",
      "People from Richmond, Virginia\n",
      "Singers from Virginia\n",
      "1960 births\n",
      "Living people  ----  0.9732881784439087\n",
      "Isabelle Yasmine Adjani (born June 27, 1955) is a French actress, producer and singer. In 2010, she was made Chevalier of the Legion of Honour. She has won more César Awards than any other performer.\n",
      "\n",
      "References\n",
      "\n",
      "Other websites\n",
      "\n",
      " \n",
      "\n",
      "French movie actors\n",
      "French television actors\n",
      "Actors from Paris\n",
      "French singers\n",
      "1955 births\n",
      "Living people  ----  0.9760726690292358\n",
      "Samantha Jane Barks (born 2 October 1990) is a Manx singer and actress who first rose to fame after coming third in the BBC talent show–themed television series I'd Do Anything in 2008. In 2012, she was cast in her first movie as Éponine in the movie version of the long-running musical Les Misérables.\n",
      "\n",
      "Filmography\n",
      "\n",
      "Awards\n",
      " 2013 Elle Style Awards for Best Breakthrough Performance - Les Misérables\n",
      " 2012 Hollywood Film Festival Hollywood Spotlight Award - Les Misérables\n",
      " 2012 National Board of Review Award for Best Cast - Les Misérables\n",
      " 2012 Satellite Award for Best Cast – Motion Picture - Les Misérables\n",
      " 2012 Washington D.C. Area Film Critics Association Award for Best Ensemble - Les Misérables\n",
      " 2012 Screen Actors Guild Award for Outstanding Performance by a Cast in a Motion Picture - Les Misérables - (nomination)\n",
      " 2012 Satellite Award for Best Supporting Actress – Motion Picture - Les Misérables - (nomination)\n",
      " 2012 San Diego Film Critics Society Award for Best Supporting Actress – Motion Picture - Les Misérables - (nomination)\n",
      " 2012 an Diego Film Critics Society Award for Best Performance by an Ensemble - Les Misérables - (nomination)\n",
      " 2012 Washington D.C. Area Film Critics Association Award for Best Supporting Actress – Motion Picture - Les Misérables - (nomination)\n",
      " 2012 Broadcast Film Critics Association Award for Best Acting Ensemble - Les Misérables - (nomination)\n",
      " 2012 London Film Critics Circle Award for Young British Performer of the Year - Les Misérables - (nomination)\n",
      " 2012 Chicago Film Critics Association Award for Most Promising Performer - Les Misérables - (nomination)\n",
      " 2012 Alliance of Women Film Journalists Award for Best Breakthrough Performance - Les Misérables - (nomination)\n",
      "\n",
      "References\n",
      "\n",
      "Other websites\n",
      " \n",
      " Samantha Barks' CV at United Agents\n",
      " \"Sam Singing Defying Defying Gravity\"—YouTube\n",
      "\n",
      "1990 births\n",
      "British singers\n",
      "Living people\n",
      "Manx people\n",
      "British movie actors\n",
      "British artists\n",
      "British television actors\n",
      "Musical theater actors  ----  0.9820640087127686\n",
      "Amanda Marshall (born August 29, 1972) is a Canadian pop-rock singer. Her self-titled first record was in 1995. It was a major success in Canada. Her most successful single was \"Birmingham\". Marshall has released many singles. She has not had a studio album since around 2001.\n",
      "\n",
      "References\n",
      "\n",
      "Other websites\n",
      "\n",
      "Singers from Toronto\n",
      "1972 births\n",
      "Living people  ----  0.9829479455947876\n",
      "Amy MacDonald is a Scottish singer and songwriter.  She became famous in 2007 with her first album This Is The Life and her first single \"Poison Prince\".  She has become even more successful in Europe since her single \"This Is The Life\" charted at number 1 in many European countries.\n",
      "\n",
      "Awards\n",
      "\n",
      "Discography\n",
      " This Is the Life (2007)\n",
      " A Curious Thing (2010)\n",
      " Life in a Beautiful Light (2012)\n",
      "\n",
      "Living people\n",
      "1987 births\n",
      "Scottish singers  ----  0.9881876707077026\n",
      "Search Time =  0.0072672367095947266\n"
     ]
    }
   ],
   "source": [
    "for hits_i, hits in enumerate(results):\n",
    "    print('Search Term: ', search_terms[hits_i])\n",
    "    print('Results: ')\n",
    "    for hit in hits:\n",
    "        print(hit.entity.get(FIELD_2_EMBED), \" ---- \", hit.distance)\n",
    "\n",
    "print('Search Time = ', endTime - startTime)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "milvus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
