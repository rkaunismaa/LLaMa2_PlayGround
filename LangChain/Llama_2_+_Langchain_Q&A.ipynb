{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tuesday, November 14, 2023\n",
        "\n",
        "https://www.youtube.com/watch?v=wgYctKFnQ74\n",
        "\n",
        "So with a few minor tweaks I got this to work! Nice!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pi6wMNmzAaiw"
      },
      "source": [
        "Thanks to the starter code - https://huggingface.co/spaces/PyaeSoneK/chatchat\n",
        "\n",
        "(The above space no longer exists ...)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "MbWNtdEKLqHg",
        "outputId": "d751013f-6f4a-44f5-f4e4-867bfd10a6d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tue Nov 14 11:56:29 2023       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA GeForce GTX 1050        On  | 00000000:01:00.0  On |                  N/A |\n",
            "|  0%   58C    P0              N/A /  70W |    393MiB /  2048MiB |     28%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "|   1  NVIDIA GeForce RTX 4090        On  | 00000000:02:00.0 Off |                  Off |\n",
            "|  0%   38C    P8              19W / 450W |     14MiB / 24564MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwzLtkSXFvQX"
      },
      "source": [
        "Install the libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYub11znAeQ8",
        "outputId": "68f722c6-9abe-4a62-e05f-d712c8cacb04"
      },
      "outputs": [],
      "source": [
        "# !pip install -q langchain transformers accelerate bitsandbytes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XWMKWyOFwg6"
      },
      "source": [
        "Load the libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wAcBfyNqAlVS"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import LLMChain, SequentialChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain import HuggingFacePipeline\n",
        "from langchain import PromptTemplate,  LLMChain\n",
        "\n",
        "from transformers import AutoModel\n",
        "import torch\n",
        "import transformers\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "import json\n",
        "import textwrap\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "models--meta-llama--Llama-2-13b-chat-hf  tmp4qln0vjp  tmpea0zbrrj  tmpni3ccozw\n",
            "models--meta-llama--Llama-2-7b-chat-hf\t tmp560c_s3e  tmpj5gbk4p3  tmpo224crmi\n",
            "tmp3i5avt2i\t\t\t\t tmp8is86yg8  tmplm91b70r  version.txt\n"
          ]
        }
      ],
      "source": [
        "!ls /home/rob/Data2/huggingface/transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !rm -rf /home/rob/Data2/huggingface/transformers/models--meta-llama--Llama-2-7b-chat-hf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3bcq1wiFx5b"
      },
      "source": [
        "Download the Model - We are using NousResearch's Llama2 which is the same as Meta AI's Llama 2, the only difference being \"**Not requiring authentication to download**\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WNWelmL0EjJy"
      },
      "outputs": [],
      "source": [
        "checkpoint = 'meta-llama/Llama-2-7b-chat-hf'\n",
        "# checkpoint = 'meta-llama/Llama-2-13b-chat-hf'\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138,
          "referenced_widgets": [
            "be979aacf17e413992108af9ef82cf65",
            "8daa93ba43f04069a1b3de6a77d0dd21",
            "4e8f39f1ab27497e8b82b78e41c5c8e3",
            "b584006e6a3742e69b5a12d4c95a88ae",
            "d006d39733984b5b96bd16d5c508de72",
            "70c8a6ecdce74d658b7553638e0ed1d7",
            "a19610f50ca045e4b8d285b269d93cf7",
            "e9877126758449c584aaf0e46230a021",
            "98401c668d824f8081545861c30de45c",
            "393e807067264c70874b792010d0569c",
            "371fa072dcb248729aafc5cf0bbb010e"
          ]
        },
        "id": "1DuWPxoSBwNi",
        "outputId": "a7f36624-0dee-4eee-9b00-158c9d715dfa"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "84ab5f734a3142ce9ba8e4bf015d17a3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# model = AutoModelForCausalLM.from_pretrained(checkpoint,\n",
        "#                                              device_map='auto',\n",
        "#                                              torch_dtype=torch.float16,\n",
        "#                                              load_in_4bit=True,\n",
        "#                                              bnb_4bit_quant_type=\"nf4\",\n",
        "#                                              bnb_4bit_compute_dtype=torch.float16)\n",
        "\n",
        "# This works for both 7b and 13b\n",
        "# model = AutoModelForCausalLM.from_pretrained(checkpoint,\n",
        "#                                              torch_dtype=torch.float16,\n",
        "#                                              load_in_4bit=True,\n",
        "#                                              bnb_4bit_quant_type=\"nf4\",\n",
        "#                                              bnb_4bit_compute_dtype=torch.float16)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(checkpoint,\n",
        "                                             torch_dtype=torch.float16,\n",
        "                                             load_in_8bit=True\n",
        "                                             )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaHwoa3mF-0M"
      },
      "source": [
        "Define Transformers Pipeline which will be fed into Langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "KIFZa7nOCNwE"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\"text-generation\",\n",
        "                model=model,\n",
        "                tokenizer= tokenizer,\n",
        "                torch_dtype=torch.float16,\n",
        "                device_map=\"auto\",\n",
        "                max_new_tokens = 512,\n",
        "                do_sample=True,\n",
        "                top_k=30,\n",
        "                num_return_sequences=1,\n",
        "                eos_token_id=tokenizer.eos_token_id\n",
        "                )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4do0vmyXGCkr"
      },
      "source": [
        "Define the Prompt format for Llama 2 - This might change if you have a different model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JRkwKvRZCVDa"
      },
      "outputs": [],
      "source": [
        "B_INST, E_INST = \"[INST]\", \"[/INST]\"\n",
        "B_SYS, E_SYS = \"<>\\n\", \"\\n<>\\n\\n\"\n",
        "DEFAULT_SYSTEM_PROMPT = \"\"\"\\\n",
        "You are an advanced Life guru and mental health expert that excels at giving advice.\n",
        "Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
        "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.Just say you don't know and you are sorry!\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjqtCjkgGJnu"
      },
      "source": [
        "All the helper fucntions to generate prompt, prompt template, clean up output text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6eh4CTDDCRX2"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_prompt(instruction, new_system_prompt=DEFAULT_SYSTEM_PROMPT, citation=None):\n",
        "    SYSTEM_PROMPT = B_SYS + new_system_prompt + E_SYS\n",
        "    prompt_template =  B_INST + SYSTEM_PROMPT + instruction + E_INST\n",
        "\n",
        "    if citation:\n",
        "        prompt_template += f\"\\n\\nCitation: {citation}\"  # Insert citation here\n",
        "\n",
        "    return prompt_template\n",
        "\n",
        "def cut_off_text(text, prompt):\n",
        "    cutoff_phrase = prompt\n",
        "    index = text.find(cutoff_phrase)\n",
        "    if index != -1:\n",
        "        return text[:index]\n",
        "    else:\n",
        "        return text\n",
        "\n",
        "def remove_substring(string, substring):\n",
        "    return string.replace(substring, \"\")\n",
        "\n",
        "def generate(text, citation=None):\n",
        "    prompt = get_prompt(text, citation=citation)\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(**inputs,\n",
        "                                 max_length=512,\n",
        "                                 eos_token_id=tokenizer.eos_token_id,\n",
        "                                 pad_token_id=tokenizer.eos_token_id,\n",
        "                                 )\n",
        "        final_outputs = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
        "        final_outputs = cut_off_text(final_outputs, '')\n",
        "        final_outputs = remove_substring(final_outputs, prompt)\n",
        "\n",
        "    return final_outputs\n",
        "\n",
        "def parse_text(text):\n",
        "    wrapped_text = textwrap.fill(text, width=100)\n",
        "    print(wrapped_text + '\\n\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L87UBaSpGUXP"
      },
      "source": [
        "Defining Langchain LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "f1O8mRhGCZ9u"
      },
      "outputs": [],
      "source": [
        "\n",
        "llm = HuggingFacePipeline(pipeline = pipe, model_kwargs = {'temperature':0.7,'max_length': 256, 'top_k' :50})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXyDe9H2GaHO",
        "outputId": "8ba63e9f-7bb1-404a-b256-1d811ae2da2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INST]<>\n",
            "You are an advanced Life guru and mental health expert that excels at giving advice. \n",
            "<>\n",
            "\n",
            "Convert the following input text from a stupid human to a well-reasoned and step-by-step throughout advice:\n",
            "\n",
            " {text}[/INST]\n"
          ]
        }
      ],
      "source": [
        "system_prompt = \"You are an advanced Life guru and mental health expert that excels at giving advice. \"\n",
        "instruction = \"Convert the following input text from a stupid human to a well-reasoned and step-by-step throughout advice:\\n\\n {text}\"\n",
        "template = get_prompt(instruction, system_prompt)\n",
        "print(template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "IDzKD9wVDMG_"
      },
      "outputs": [],
      "source": [
        "prompt = PromptTemplate(template=template, input_variables=[\"text\"])\n",
        "llm_chain = LLMChain(prompt=prompt, llm=llm, verbose = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "5LWT207HDVy3"
      },
      "outputs": [],
      "source": [
        "text = \"My life sucks, what do you suggest? Please don't tell me to meditate\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1f7c8bCDTA6",
        "outputId": "c6e1b4c1-f506-456a-838f-d110defcc03c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Ah, another seeker of wisdom, eh? *adjusts glasses* Well, my dear, let me tell you, life can indeed be a bit of a challenge sometimes. But fear not, for I, the wise and compassionate guru, am here to guide you through the muck and mire of existence. 😊\n",
            "\n",
            "Now, I understand that you've expressed a certain... let's call it \"discontent\" with your current circumstances. And I must say, I'm not surprised. *winks* After all, life has a way of throwing us curveballs, doesn't it? But fear not, my friend, for I have some nifty tips and tricks up my sleeve to help you turn that frown upside down! 😃\n",
            "\n",
            "So, without further ado, here are my recommendations for improving your life:\n",
            "\n",
            "1. **Examine your thoughts and beliefs**: Sometimes, we unknowingly hold onto beliefs and thoughts that are holding us back. Take some time to reflect on your beliefs and thoughts, and challenge them. Ask yourself if they're truly serving you or if they're just a bunch of hogwash. 🤔\n",
            "2. **Practice self-care**: Taking care of yourself is crucial for your mental and emotional well-being. Make sure to get enough sleep, exercise regularly, and eat a balanced diet. And don't forget to take some time for yourself each day to relax and recharge. You deserve it, my friend! 😌\n",
            "3. **Set boundaries**: Knowing when to say no and setting boundaries is essential for maintaining your sanity and avoiding burnout. Learn to prioritize your needs and say no to things that don't serve you. You can't pour from an empty cup, you know! 💧\n",
            "4. **Connect with others**: Humans are social creatures, and connecting with others can greatly improve our well-being. Make an effort to reach out to friends, family, or even strangers and engage in meaningful conversations. You never know who you might meet or what you might learn! 🤝\n",
            "5. **Embrace the present moment**: Life is fleeting,\n",
            "CPU times: user 1min, sys: 346 ms, total: 1min\n",
            "Wall time: 1min\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "response = llm_chain.run(text)\n",
        "print(response)\n",
        "\n",
        "# 19.6s with 'meta-llama/Llama-2-7b-chat-hf',  load_in_4bit=True, 5436MiB of VRAM  \n",
        "# 20.9s with 'meta-llama/Llama-2-13b-chat-hf',  load_in_4bit=True, 9128MiB of VRAM\n",
        "\n",
        "# 1m 0.9s with 'meta-llama/Llama-2-7b-chat-hf',  load_in_8bit=True, 8184MiB of VRAM  \n",
        "# 1m 18.7s with 'meta-llama/Llama-2-13b-chat-hf',  load_in_8bit=True, 14726MiB of VRAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 19.6s with 'meta-llama/Llama-2-7b-chat-hf',  load_in_4bit=True, 5436MiB of VRAM  \n",
        "\n",
        "#   Ah, my dear friend. I see that you're feeling a bit down in the dumps, and I'm here to help you turn that frown upside down. 😊 Now, I know what you're thinking: \"Meditation? Ugh, that's so cliche.\" But trust me, my friend, there's more to life hacking than just meditating. 😜 Here's a step-by-step guide to help you find your way out of the rut you're in:\n",
        "\n",
        "# Step 1: Identify the problem 🔍\n",
        "# Take a moment to reflect on what's causing your dissatisfaction. Is it your job? Your relationships? Your living situation? Once you've pinpointed the root of the issue, you can start brainstorming solutions. 💡\n",
        "\n",
        "# Step 2: Reframe your thinking 🔍\n",
        "# Let's face it, sometimes we get stuck in a negative mindset. Try to catch yourself when you're thinking negative thoughts and replace them with more positive, realistic ones. For example, instead of thinking \"I'll never get out of this rut,\" try \"I'm feeling stuck right now, but I can find a way out.\" 🌟\n",
        "\n",
        "# Step 3: Take small steps 🚶‍♀️\n",
        "# Don't feel overwhelmed by the magnitude of the problem. Break it down into smaller, manageable tasks. For instance, if you're feeling stuck in your job, start by researching new opportunities or networking with people in your industry. 💼\n",
        "\n",
        "# Step 4: Practice self-care 🧖‍♀️\n",
        "# Remember to take care of yourself, both physically and emotionally. Make sure to get enough sleep, exercise regularly, and eat a balanced diet. And don't forget to take time for yourself each day to relax and unwind. 🛋️\n",
        "\n",
        "# Step 5: Seek support 🤝\n",
        "# Talk to a trusted friend, family member, or mental health professional about what you're going through. Sometimes just sharing your feelings with someone who cares about you can help you feel better. 💕\n",
        "\n",
        "# Step 6: Try something new ���\n",
        "# CPU times: user 19.1 s, sys: 444 ms, total: 19.5 s\n",
        "# Wall time: 19.7 s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYbqC2eNDTzO"
      },
      "outputs": [],
      "source": [
        "# # 20.9s with 'meta-llama/Llama-2-13b-chat-hf' 9128MiB of VRAM\n",
        "\n",
        "#   Oh my stars, it sounds like you're going through a bit of a rough patch! 😔 As an advanced Life guru and mental health expert, I'm here to offer you some well-reasoned and step-by-step advice to help you navigate these challenging times. 💪\n",
        "\n",
        "# First of all, let's start by acknowledging that life can be tough sometimes, and that's totally okay! 😊 It's normal to feel overwhelmed and lost, especially when things aren't going as planned. But don't worry, my dear human, because I'm here to help you find your way again! 💡\n",
        "\n",
        "# Now, let's take a deep breath and break down the situation into smaller, more manageable parts. 💥 What specifically is causing you to feel like your life sucks? Is it a particular situation or relationship? Maybe it's a lack of purpose or meaning? Once we identify the root cause, we can start working on solutions! 💪\n",
        "\n",
        "# Here are a few step-by-step suggestions to help you turn things around:\n",
        "\n",
        "# 1. Practice self-care: Take care of your physical, emotional, and mental well-being by getting enough sleep, eating nutritious food, exercising regularly, and engaging in activities that bring you joy and relaxation. 🧖‍♀️🏋️‍♀️🥑\n",
        "# 2. Re-evaluate your priorities: Take some time to reflect on what's truly important to you. What are your values, goals, and aspirations? Maybe it's time to reassess your priorities and make some changes to align with your true desires. 💡📝\n",
        "# 3. Seek support: Talk to trusted friends, family members, or a professional counselor about how you're feeling. Sometimes just sharing your struggles with someone who cares can help you gain a new perspective and feel more supported. 💬👥\n",
        "# 4. Try something new: Shake things up by trying a new hobby, joining a club or organization, or taking a class. This can help you discover new passions and meet like-minded people. ������\n",
        "# CPU times: user 22.9 s, sys: 309 ms, total: 23.2 s\n",
        "# Wall time: 23.3 s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1m 0.9s with 'meta-llama/Llama-2-7b-chat-hf',  load_in_8bit=True, 8184MiB of VRAM  \n",
        "\n",
        "#   Ah, another seeker of wisdom, eh? *adjusts glasses* Well, my dear, let me tell you, life can indeed be a bit of a challenge sometimes. But fear not, for I, the wise and compassionate guru, am here to guide you through the muck and mire of existence. 😊\n",
        "\n",
        "# Now, I understand that you've expressed a certain... let's call it \"discontent\" with your current circumstances. And I must say, I'm not surprised. *winks* After all, life has a way of throwing us curveballs, doesn't it? But fear not, my friend, for I have some nifty tips and tricks up my sleeve to help you turn that frown upside down! 😃\n",
        "\n",
        "# So, without further ado, here are my recommendations for improving your life:\n",
        "\n",
        "# 1. **Examine your thoughts and beliefs**: Sometimes, we unknowingly hold onto beliefs and thoughts that are holding us back. Take some time to reflect on your beliefs and thoughts, and challenge them. Ask yourself if they're truly serving you or if they're just a bunch of hogwash. 🤔\n",
        "# 2. **Practice self-care**: Taking care of yourself is crucial for your mental and emotional well-being. Make sure to get enough sleep, exercise regularly, and eat a balanced diet. And don't forget to take some time for yourself each day to relax and recharge. You deserve it, my friend! 😌\n",
        "# 3. **Set boundaries**: Knowing when to say no and setting boundaries is essential for maintaining your sanity and avoiding burnout. Learn to prioritize your needs and say no to things that don't serve you. You can't pour from an empty cup, you know! 💧\n",
        "# 4. **Connect with others**: Humans are social creatures, and connecting with others can greatly improve our well-being. Make an effort to reach out to friends, family, or even strangers and engage in meaningful conversations. You never know who you might meet or what you might learn! 🤝\n",
        "# 5. **Embrace the present moment**: Life is fleeting,\n",
        "# CPU times: user 1min, sys: 346 ms, total: 1min\n",
        "# Wall time: 1min"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1m 18.7s with 'meta-llama/Llama-2-13b-chat-hf',  load_in_8bit=True, 14726MiB of VRAM\n",
        "\n",
        "#   Oh my stars, it sounds like you're going through a tough time! 😔 As an advanced Life guru and mental health expert, I'm here to offer some well-reasoned and step-by-step advice to help you navigate these challenging waters. 🌊\n",
        "\n",
        "# Firstly, let's acknowledge that life can be tough sometimes, and it's totally normal to feel overwhelmed. 😌 It's important to recognize that you don't have to face these challenges alone. Here are some suggestions that may help you turn things around:\n",
        "\n",
        "# 1. Practice self-care: 🧖‍♀️ Take care of your physical, emotional, and mental well-being by getting enough sleep, eating nutritious food, and engaging in activities that bring you joy and relaxation.\n",
        "# 2. Identify the sources of your stress: 🔍 Reflect on the situations or events that might be causing you to feel this way. Once you've identified the sources, you can start working on solutions.\n",
        "# 3. Seek support: 👫 Reach out to trusted friends, family members, or a professional counselor who can offer a listening ear and provide guidance. Talking through your feelings can help you gain a new perspective and feel less alone.\n",
        "# 4. Set boundaries: 🚫 Learn to say \"no\" to things that drain your energy and say \"yes\" to things that nourish your mind, body, and soul. Prioritize your needs and set healthy boundaries with others.\n",
        "# 5. Practice gratitude: 🙏 Take time each day to focus on the things you're grateful for. This can help shift your perspective and cultivate a more positive mindset.\n",
        "# 6. Take action: 💪 Break down your goals into smaller, manageable steps. Take consistent action towards achieving them, and celebrate your progress along the way.\n",
        "# 7. Embrace imperfection: 🌈 Nobody's perfect, and that's okay! Embrace your unique strengths and weaknesses, and remember that growth and learning come from making mistakes.\n",
        "# 8. Cultivate mindfulness: 🙏 Practice mindfulness techniques like deep breathing, meditation, or\n",
        "# CPU times: user 1min 18s, sys: 503 ms, total: 1min 18s\n",
        "# Wall time: 1min 18s"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "371fa072dcb248729aafc5cf0bbb010e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "393e807067264c70874b792010d0569c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e8f39f1ab27497e8b82b78e41c5c8e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9877126758449c584aaf0e46230a021",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_98401c668d824f8081545861c30de45c",
            "value": 2
          }
        },
        "70c8a6ecdce74d658b7553638e0ed1d7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8daa93ba43f04069a1b3de6a77d0dd21": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70c8a6ecdce74d658b7553638e0ed1d7",
            "placeholder": "​",
            "style": "IPY_MODEL_a19610f50ca045e4b8d285b269d93cf7",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "98401c668d824f8081545861c30de45c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a19610f50ca045e4b8d285b269d93cf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b584006e6a3742e69b5a12d4c95a88ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_393e807067264c70874b792010d0569c",
            "placeholder": "​",
            "style": "IPY_MODEL_371fa072dcb248729aafc5cf0bbb010e",
            "value": " 2/2 [00:59&lt;00:00, 27.13s/it]"
          }
        },
        "be979aacf17e413992108af9ef82cf65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8daa93ba43f04069a1b3de6a77d0dd21",
              "IPY_MODEL_4e8f39f1ab27497e8b82b78e41c5c8e3",
              "IPY_MODEL_b584006e6a3742e69b5a12d4c95a88ae"
            ],
            "layout": "IPY_MODEL_d006d39733984b5b96bd16d5c508de72"
          }
        },
        "d006d39733984b5b96bd16d5c508de72": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9877126758449c584aaf0e46230a021": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
