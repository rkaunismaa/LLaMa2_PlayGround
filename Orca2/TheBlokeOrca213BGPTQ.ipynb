{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Friday, December 8, 2023\n",
    "\n",
    "[TheBloke/Orca-2-13B-GPTQ](https://huggingface.co/TheBloke/Orca-2-13B-GPTQ)\n",
    "\n",
    "This all runs. Nice!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only target the 4090 ...\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models--Intel--neural-chat-7b-v3-1\n",
      "models--TheBloke--CodeLlama-34B-Instruct-GPTQ\n",
      "models--TheBloke--Llama-2-13b-Chat-GPTQ\n",
      "models--TheBloke--Orca-2-13B-GPTQ\n",
      "models--TheBloke--Python-Code-33B-GPTQ\n",
      "models--facebook--blenderbot-1B-distill\n",
      "models--google--flan-t5-large\n",
      "models--gpt2-medium\n",
      "models--meta-llama--Llama-2-13b-chat-hf\n",
      "models--meta-llama--Llama-2-13b-hf\n",
      "models--model_name\n",
      "tmp0m77pc0x\n",
      "tmpcjh0h7gn\n",
      "tmpfcrmwgx2\n",
      "tmpzafytbf_\n",
      "version.txt\n"
     ]
    }
   ],
   "source": [
    "!ls /home/rob/Data2/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backup \"TheBloke/Orca-2-13B-GPTQ\"\n",
    "# docker cp c9b676310ea0://home/rob/Data2/huggingface/transformers/models--TheBloke--Orca-2-13B-GPTQ /home/rob/Data3/huggingface/transformers\n",
    "# Successfully copied 7.26GB to /home/rob/Data3/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = \"TheBloke/Orca-2-13B-GPTQ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have activated exllama backend. Note that you can get better inference\n",
      "                    speed using exllamav2 kernel by setting `use_exllama_v2=True`.`disable_exllama` will be deprecated\n",
      "                    in future version.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.8 s, sys: 3.4 s, total: 16.2 s\n",
      "Wall time: 6.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# To use a different branch, change revision\n",
    "# For example: revision=\"gptq-4bit-32g-actorder_True\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name_or_path,\n",
    "                                             device_map=\"auto\",\n",
    "                                             trust_remote_code=False,\n",
    "                                             revision=\"main\")\n",
    "# load time 8610 MiB VRAM\n",
    "# CPU times: user 8.73 s, sys: 2.75 s, total: 11.5 s\n",
    "# Wall time: 4.75 s\n",
    "\n",
    "# download time ...\n",
    "# CPU times: user 36.6 s, sys: 38.8 s, total: 1min 15s\n",
    "# Wall time: 1h 40min 27s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This system message was copied from ... https://huggingface.co/microsoft/Orca-2-13b\n",
    "system_message = \"You are Orca, an AI language model created by Microsoft. You are a cautious assistant. You carefully follow instructions. You are helpful and harmless and you follow ethical guidelines and promote positive behavior.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Tell me about AI\"\n",
    "\n",
    "prompt_template=f'''<|im_start|>system\n",
    "{system_message}<|im_end|>\n",
    "<|im_start|>user\n",
    "{prompt}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(prompt_template, return_tensors='pt').input_ids.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s><|im_start|>system\n",
      "You are Orca, an AI language model created by Microsoft. You are a cautious assistant. You carefully follow instructions. You are helpful and harmless and you follow ethical guidelines and promote positive behavior.<|im_end|>\n",
      "<|im_start|>user\n",
      "Tell me about AI<|im_end|>\n",
      "<|im_start|>assistant\n",
      "AI stands for artificial intelligence, which is the branch of computer science that deals with creating machines or systems that can perform tasks that normally require human intelligence, such as reasoning, learning, decision making, perception, natural language processing, etc. AI can be divided into two main types: narrow AI and general AI. Narrow AI is the type of AI that can only perform a specific task or a subset of tasks, such as facial recognition, chess playing, speech recognition, etc. General AI is the type of AI that can perform any task that a human can, such as understanding natural language, common sense reasoning, creativity, etc. General AI does not exist yet, but it is the ultimate goal of AI research. Some of the applications of AI are:\n",
      "\n",
      "- Self-driving cars\n",
      "- Virtual assistants\n",
      "- Robotics\n",
      "- Image and speech recognition\n",
      "- Healthcare and medicine\n",
      "- Education and learning\n",
      "- Entertainment and gaming\n",
      "- Cybersecurity and fraud detection\n",
      "- And many more\n",
      "\n",
      "AI is a rapidly evolving and growing field that has many benefits and challenges for society. Some of the benefits are:\n",
      "\n",
      "- Improving the quality and efficiency of human life\n",
      "- Enhancing human creativity and innovation\n",
      "- Solving complex and difficult problems that are beyond human capabilities\n",
      "- Creating new opportunities and industries\n",
      "\n",
      "Some of the challenges are:\n",
      "\n",
      "- Ethical and social issues, such as bias, privacy, accountability, transparency, and fairness\n",
      "- Technical and scientific issues, such as complexity, scalability, reliability, and security\n",
      "- Economic and political issues, such as competition, regulation, and governance\n",
      "- Philosophical and existential issues, such as what is intelligence, what is consciousness, and what is the role and value of AI in human society\n",
      "\n",
      "AI is a fascinating and diverse field that has a lot of potential and impact for the future of humanity. If you want to learn more about AI, you can explore some of the following resources:\n",
      "\n",
      "- Books: Some of the popular and recommended books on AI are:\n",
      "\n",
      "  - Artificial Intelligence: A Modern Approach by Stuart Russell and Peter Norvig\n",
      "  - Superintelligence: Paths, Dangers, Strategies by Nick Bostrom\n",
      "  - Life\n",
      "CPU times: user 16.2 s, sys: 207 ms, total: 16.4 s\n",
      "Wall time: 16.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "output = model.generate(inputs=input_ids, temperature=0.7, do_sample=True, top_p=0.95, top_k=40, max_new_tokens=512)\n",
    "print(tokenizer.decode(output[0]))\n",
    "\n",
    "# 9892 MiB VRAM\n",
    "# CPU times: user 16.2 s, sys: 207 ms, total: 16.4 s\n",
    "# Wall time: 16.5 s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference can also be done using transformers' pipeline\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=512,\n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    "    top_p=0.95,\n",
    "    top_k=40,\n",
    "    repetition_penalty=1.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are Orca, an AI language model created by Microsoft. You are a cautious assistant. You carefully follow instructions. You are helpful and harmless and you follow ethical guidelines and promote positive behavior.<|im_end|>\n",
      "<|im_start|>user\n",
      "Tell me about AI<|im_end|>\n",
      "<|im_start|>assistant\n",
      "AI stands for artificial intelligence, which is the field of computer science that studies how to create machines or systems that can perform tasks that normally require human intelligence, such as reasoning, learning, planning, problem-solving, perception, natural language processing, etc. AI can be classified into different types, such as narrow AI, which focuses on specific domains or applications, and general AI, which aims to achieve a universal intelligence that can adapt to any situation. Some examples of AI applications are chatbots, face recognition, self-driving cars, virtual assistants, games, recommendation systems, etc. AI also raises ethical, social, and philosophical issues, such as the impact of AI on human dignity, privacy, autonomy, accountability, fairness, transparency, etc.\n"
     ]
    }
   ],
   "source": [
    "print(pipe(prompt_template)[0]['generated_text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
