{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wednesday, January 10, 2024\n",
    "\n",
    "Run this in the container hfpt_Dec14\n",
    "\n",
    "#### Thursday, November 9, 2023\n",
    "\n",
    "Determine the size of the models in the transformers folder. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformersFolder = '/home/rob/Data2/huggingface/transformers'\n",
    "# different for the container hfpt_Dec14\n",
    "transformersFolder = '/root/.cache/huggingface/hub'\n",
    "\n",
    "# Wednesday, January 10, 2024\n",
    "# hfpt_Dec14\n",
    "# Total file size of all folders: 381,939,169,491\n",
    "\n",
    "# Let's torch the folder of all files and then see how much space it frees up ...\n",
    "# Before: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What about the total size of everything in the huggingface folder?\n",
    "transformersFolder = '/root/.cache/huggingface'\n",
    "\n",
    "# Wednesday, January 10, 2024\n",
    "# hfpt_Dec14\n",
    "# Total file size of all folders: 844,446,596,190\n",
    "# Wow! Really!! That much space! Damn!\n",
    "\n",
    "# Ok, I think this is wrong ...\n",
    "\n",
    "# (base) rob@KAUWITB:~$ docker ps --size\n",
    "# CONTAINER ID   IMAGE           COMMAND                  CREATED       STATUS          PORTS                                                                                  NAMES        SIZE\n",
    "# c8324b70601d   hfpt:20231214   \"/opt/nvidia/nvidia_â€¦\"   3 weeks ago   Up 13 seconds   0.0.0.0:6006->6006/tcp, :::6006->6006/tcp, 0.0.0.0:8888->8888/tcp, :::8888->8888/tcp   hfpt_Dec14   247GB (virtual 267GB)\n",
    "\n",
    "# Disk Usage Analyzer reports 769.5 GB used, 694071 items ...\n",
    "\n",
    "# Now let's torch all models in the /root/.cache/huggingface/hub folder, then see how much space you have ...\n",
    "\n",
    "# WTF!? Disk Usage Analyzer still shows the same usage!! \n",
    "# I know Disk Usage Analyzer cannot see the docker-data folder ... maybe that is the reason for this ...\n",
    "# ... yeah , that makes sense ... in the future, you need to use the Disks Utility ... like right now, it shows 897GB free ...\n",
    "# Gonna torch all models in the hub folder ... again ... \n",
    "# Yup! Disks now shows 925 GB free ... so this is correct. \n",
    "\n",
    "# The below results seem correct! ... \n",
    "\n",
    "# (base) rob@KAUWITB:~$ docker ps --size\n",
    "# CONTAINER ID   IMAGE           COMMAND                  CREATED       STATUS          PORTS                                                                                  NAMES        SIZE\n",
    "# c8324b70601d   hfpt:20231214   \"/opt/nvidia/nvidia_â€¦\"   3 weeks ago   Up 22 minutes   0.0.0.0:6006->6006/tcp, :::6006->6006/tcp, 0.0.0.0:8888->8888/tcp, :::8888->8888/tcp   hfpt_Dec14   26.3GB (virtual 46.9GB)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf /root/.cache/huggingface/hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir /root/.cache/huggingface/hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformersFolder = '/root/.cache/huggingface/datasets'\n",
    "\n",
    "# Total file size of all folders: 13,142,291,016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformersFolder = '/root/.cache/huggingface/modules'\n",
    "\n",
    "# Total file size of all folders: 558,776"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformersFolder = '/root/.cache/huggingface/token'\n",
    "# hmm can't scan this ...meh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/root/.cache/huggingface/hub': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# !ls /home/rob/Data2/huggingface/transformers\n",
    "!ls /root/.cache/huggingface/hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backup any model shown above that has not already been backed up to either '/home/rob/Data2/huggingface/transformers' or '/home/rob/Data3/huggingface/transformers'\n",
    "\n",
    "# docker cp c8324b70601d://root/.cache/huggingface/hub/models--dn118--unaestheticXL /home/rob/Data3/huggingface/transformers\n",
    "# Successfully copied 39.4kB to /home/rob/Data3/huggingface/transformers\n",
    "\n",
    "# docker cp c8324b70601d://root/.cache/huggingface/hub/models--kandinsky-community--kandinsky-2-2-prior /home/rob/Data3/huggingface/transformers\n",
    "# Successfully copied 10.6GB to /home/rob/Data3/huggingface/transformers\n",
    "\n",
    "# docker cp c8324b70601d://root/.cache/huggingface/hub/models--sd-concepts-library--cat-toy /home/rob/Data3/huggingface/transformers\n",
    "# Successfully copied 11.3kB to /home/rob/Data3/huggingface/transformers\n",
    "\n",
    "# docker cp c8324b70601d://root/.cache/huggingface/hub/models--stabilityai--stable-diffusion-xl-base-1.0 /home/rob/Data3/huggingface/transformers\n",
    "# Successfully copied 7.11GB to /home/rob/Data3/huggingface/transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below was generated by [chatgpt](https://chat.openai.com/c/857d7961-fd72-4019-bfc6-61600a67410b)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 60\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTotal file size of all folders: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_size_formatted\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 60\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 52\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSize\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSize\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(format_size_with_commas)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Calculate the total file size of all folders summed\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m total_size \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m     53\u001b[0m total_size_formatted \u001b[38;5;241m=\u001b[39m format_size_with_commas(total_size)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSubfolder sizes (sorted with commas):\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/generic.py:5989\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   5983\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[1;32m   5984\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[1;32m   5985\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[1;32m   5986\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5987\u001b[0m ):\n\u001b[1;32m   5988\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[0;32m-> 5989\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/accessor.py:224\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[0;32m--> 224\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/strings/accessor.py:181\u001b[0m, in \u001b[0;36mStringMethods.__init__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstring_\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StringDtype\n\u001b[0;32m--> 181\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_categorical \u001b[38;5;241m=\u001b[39m is_categorical_dtype(data\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, StringDtype)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/strings/accessor.py:235\u001b[0m, in \u001b[0;36mStringMethods._validate\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    232\u001b[0m inferred_dtype \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39minfer_dtype(values, skipna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inferred_dtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_types:\n\u001b[0;32m--> 235\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only use .str accessor with string values!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inferred_dtype\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def get_folder_size(folder_path):\n",
    "    total_size = 0\n",
    "\n",
    "    for dirpath, dirnames, filenames in os.walk(folder_path):\n",
    "        for filename in filenames:\n",
    "            file_path = os.path.join(dirpath, filename)\n",
    "            total_size += os.path.getsize(file_path)\n",
    "\n",
    "    return total_size\n",
    "\n",
    "def get_subfolder_sizes(parent_folder):\n",
    "    subfolder_sizes = {}\n",
    "\n",
    "    for dirpath, dirnames, _ in os.walk(parent_folder):\n",
    "        for dirname in dirnames:\n",
    "            folder_path = os.path.join(dirpath, dirname)\n",
    "            total_size = get_folder_size(folder_path)\n",
    "            subfolder_sizes[dirname] = total_size\n",
    "\n",
    "    return subfolder_sizes\n",
    "\n",
    "def format_size_with_commas(size):\n",
    "    return \"{:,}\".format(size)\n",
    "\n",
    "def main():\n",
    "    \n",
    "     # folder_path = input(\"Enter the folder path: \")\n",
    "    folder_path = transformersFolder\n",
    "\n",
    "    if not os.path.exists(folder_path) or not os.path.isdir(folder_path):\n",
    "        print(\"Invalid folder path. Please provide a valid folder path.\")\n",
    "        return\n",
    "\n",
    "    subfolder_sizes = get_subfolder_sizes(folder_path)\n",
    "\n",
    "    # Create a pandas DataFrame\n",
    "    df = pd.DataFrame(list(subfolder_sizes.items()), columns=['Folder', 'Size'])\n",
    "\n",
    "    # Convert the 'Size' column to integers for sorting\n",
    "    df['Size'] = df['Size'].astype(int)\n",
    "\n",
    "    # Sort the DataFrame by 'Size' in descending order\n",
    "    df = df.sort_values(by='Size', ascending=False)\n",
    "\n",
    "    # Format the 'Size' column with commas\n",
    "    df['Size'] = df['Size'].apply(format_size_with_commas)\n",
    "\n",
    "    # Calculate the total file size of all folders summed\n",
    "    total_size = df['Size'].str.replace(',', '', regex=True).astype(int).sum()\n",
    "    total_size_formatted = format_size_with_commas(total_size)\n",
    "\n",
    "    print(\"\\nSubfolder sizes (sorted with commas):\")\n",
    "    print(df)\n",
    "    print(f\"\\nTotal file size of all folders: {total_size_formatted}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gonna kill some stuff and see if it breaks anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models--bert-base-cased\n",
      "models--bigscience--bloomz-560m\n",
      "models--decapoda-research--llama-13b-hf\n",
      "models--facebook--bart-large-cnn\n",
      "models--google--pegasus-cnn_dailymail\n",
      "models--google--vit-base-patch16-224-in21k\n",
      "models--gpt2\n",
      "models--gpt2-xl\n",
      "models--meta-llama--Llama-2-13b-hf\n",
      "models--meta-llama--Llama-2-7b-chat-hf\n",
      "models--meta-llama--Llama-2-7b-hf\n",
      "models--mistralai--Mistral-7B-Instruct-v0.1\n",
      "models--mistralai--Mistral-7B-v0.1\n",
      "models--nvidia--mit-b0\n",
      "models--openai-gpt\n",
      "models--roberta-large\n",
      "models--robkayinto--vit-base-patch16-224-in21k-finetuned-lora-food101\n",
      "models--t5-large\n",
      "models--transformersbook--pegasus-samsum\n",
      "models--xlm-roberta-base\n",
      "tmp3i5avt2i\n",
      "tmp560c_s3e\n",
      "tmp8is86yg8\n",
      "tmpea0zbrrj\n",
      "tmplm91b70r\n",
      "tmpni3ccozw\n",
      "tmpo224crmi\n",
      "version.txt\n"
     ]
    }
   ],
   "source": [
    "# !ls /home/rob/Data2/huggingface/transformers\n",
    "!ls /root/.cache/huggingface/hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf /home/rob/Data2/huggingface/transformers/models--meta-llama--Llama-2-7b-chat-hf\n",
    "# docker cp /home/rob/Data2/huggingface/transformers/models--meta-llama--Llama-2-7b-chat-hf c9b676310ea0://home/rob/Data2/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (base) rob@KAUWITB:~$ docker cp c9b676310ea0://home/rob/Data2/huggingface/transformers/models--bert-base-cased  /home/rob/Data3/huggingface/transformers\n",
    "# Successfully copied 662kB to /home/rob/Data3/huggingface/transformers\n",
    "# (base) rob@KAUWITB:~$ docker cp c9b676310ea0://home/rob/Data2/huggingface/transformers/models--bigscience--bloomz-560m  /home/rob/Data3/huggingface/transformers\n",
    "# Successfully copied 1.13GB to /home/rob/Data3/huggingface/transformers\n",
    "# (base) rob@KAUWITB:~$ docker cp c9b676310ea0://home/rob/Data2/huggingface/transformers/models--decapoda-research--llama-13b-hf  /home/rob/Data3/huggingface/transformers\n",
    "# Successfully copied 1.54kB to /home/rob/Data3/huggingface/transformers\n",
    "# (base) rob@KAUWITB:~$ docker cp c9b676310ea0://home/rob/Data2/huggingface/transformers/models--facebook--bart-large-cnn  /home/rob/Data3/huggingface/transformers\n",
    "# Successfully copied 1.63GB to /home/rob/Data3/huggingface/transformers\n",
    "# (base) rob@KAUWITB:~$ docker cp c9b676310ea0://home/rob/Data2/huggingface/transformers/models--google--pegasus-cnn_dailymail  /home/rob/Data3/huggingface/transformers\n",
    "# Successfully copied 2.28GB to /home/rob/Data3/huggingface/transformers\n",
    "# (base) rob@KAUWITB:~$ docker cp c9b676310ea0://home/rob/Data2/huggingface/transformers/models--google--vit-base-patch16-224-in21k  /home/rob/Data3/huggingface/transformers\n",
    "# Successfully copied 346MB to /home/rob/Data3/huggingface/transformers\n",
    "# (base) rob@KAUWITB:~$ docker cp c9b676310ea0://home/rob/Data2/huggingface/transformers/models--gpt2  /home/rob/Data3/huggingface/transformers\n",
    "# Successfully copied 551MB to /home/rob/Data3/huggingface/transformers\n",
    "# (base) rob@KAUWITB:~$ docker cp c9b676310ea0://home/rob/Data2/huggingface/transformers/models--gpt2-xl  /home/rob/Data3/huggingface/transformers\n",
    "# Successfully copied 6.43GB to /home/rob/Data3/huggingface/transformers\n",
    "# (base) rob@KAUWITB:~$ docker cp c9b676310ea0://home/rob/Data2/huggingface/transformers/models--nvidia--mit-b0  /home/rob/Data3/huggingface/transformers\n",
    "# Successfully copied 14.5MB to /home/rob/Data3/huggingface/transformers\n",
    "# (base) rob@KAUWITB:~$ docker cp c9b676310ea0://home/rob/Data2/huggingface/transformers/models--openai-gpt  /home/rob/Data3/huggingface/transformers\n",
    "# Successfully copied 481MB to /home/rob/Data3/huggingface/transformers\n",
    "# (base) rob@KAUWITB:~$ docker cp c9b676310ea0://home/rob/Data2/huggingface/transformers/models--roberta-large  /home/rob/Data3/huggingface/transformers\n",
    "# Successfully copied 1.42GB to /home/rob/Data3/huggingface/transformers\n",
    "# (base) rob@KAUWITB:~$ docker cp c9b676310ea0://home/rob/Data2/huggingface/transformers/models--t5-large  /home/rob/Data3/huggingface/transformers\n",
    "# Successfully copied 2.95GB to /home/rob/Data3/huggingface/transformers\n",
    "# (base) rob@KAUWITB:~$ docker cp c9b676310ea0://home/rob/Data2/huggingface/transformers/models--transformersbook--pegasus-samsum  /home/rob/Data3/huggingface/transformers\n",
    "# Successfully copied 2.29GB to /home/rob/Data3/huggingface/transformers\n",
    "# (base) rob@KAUWITB:~$ docker cp c9b676310ea0://home/rob/Data2/huggingface/transformers/models--xlm-roberta-base  /home/rob/Data3/huggingface/transformers\n",
    "# Successfully copied 1.13GB to /home/rob/Data3/huggingface/transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data2 started with 290gb free ... then I started whacking these folders ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--bert-base-cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--bigscience--bloomz-560m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--decapoda-research--llama-13b-hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--facebook--bart-large-cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--google--pegasus-cnn_dailymail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--google--vit-base-patch16-224-in21k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--gpt2-xl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--nvidia--mit-b0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--openai-gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--roberta-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--t5-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--transformersbook--pegasus-samsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--xlm-roberta-base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, now let's see what we have ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models--meta-llama--Llama-2-13b-hf\n",
      "models--meta-llama--Llama-2-7b-chat-hf\n",
      "models--meta-llama--Llama-2-7b-hf\n",
      "models--mistralai--Mistral-7B-Instruct-v0.1\n",
      "models--mistralai--Mistral-7B-v0.1\n",
      "models--robkayinto--vit-base-patch16-224-in21k-finetuned-lora-food101\n",
      "tmp3i5avt2i\n",
      "tmp560c_s3e\n",
      "tmp8is86yg8\n",
      "tmpea0zbrrj\n",
      "tmplm91b70r\n",
      "tmpni3ccozw\n",
      "tmpo224crmi\n",
      "version.txt\n"
     ]
    }
   ],
   "source": [
    "!ls /home/rob/Data2/huggingface/transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK ... now we have 310gb free ... keep going ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--meta-llama--Llama-2-13b-hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--meta-llama--Llama-2-7b-chat-hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--meta-llama--Llama-2-7b-hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--mistralai--Mistral-7B-Instruct-v0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--mistralai--Mistral-7B-v0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, have another looksee ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models--robkayinto--vit-base-patch16-224-in21k-finetuned-lora-food101\n",
      "tmp3i5avt2i\n",
      "tmp560c_s3e\n",
      "tmp8is86yg8\n",
      "tmpea0zbrrj\n",
      "tmplm91b70r\n",
      "tmpni3ccozw\n",
      "tmpo224crmi\n",
      "version.txt\n"
     ]
    }
   ],
   "source": [
    "!ls /home/rob/Data2/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--robkayinto--vit-base-patch16-224-in21k-finetuned-lora-food101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp3i5avt2i  tmp8is86yg8  tmplm91b70r  tmpo224crmi\n",
      "tmp560c_s3e  tmpea0zbrrj  tmpni3ccozw  version.txt\n"
     ]
    }
   ],
   "source": [
    "!ls /home/rob/Data2/huggingface/transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK ... there is now 393gb free ... ok, thats good enough for now ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
