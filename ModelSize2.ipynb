{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wednesday, January 10, 2024\n",
    "\n",
    "Run this in the container hfpt_Dec14\n",
    "\n",
    "#### Thursday, November 9, 2023\n",
    "\n",
    "Determine the size of the models in the transformers folder. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformersFolder = '/home/rob/Data2/huggingface/transformers'\n",
    "# different for the container hfpt_Dec14\n",
    "transformersFolder = '/root/.cache/huggingface/hub'\n",
    "\n",
    "# Wednesday, January 10, 2024\n",
    "# hfpt_Dec14\n",
    "# Total file size of all folders: 381,939,169,491\n",
    "\n",
    "# Let's torch the folder of all files and then see how much space it frees up ...\n",
    "# Before: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What about the total size of everything in the huggingface folder?\n",
    "transformersFolder = '/root/.cache/huggingface'\n",
    "\n",
    "# Wednesday, January 10, 2024\n",
    "# hfpt_Dec14\n",
    "# Total file size of all folders: 844,446,596,190\n",
    "# Wow! Really!! That much space! Damn!\n",
    "\n",
    "# Ok, I think this is wrong ...\n",
    "\n",
    "# (base) rob@KAUWITB:~$ docker ps --size\n",
    "# CONTAINER ID   IMAGE           COMMAND                  CREATED       STATUS          PORTS                                                                                  NAMES        SIZE\n",
    "# c8324b70601d   hfpt:20231214   \"/opt/nvidia/nvidia_…\"   3 weeks ago   Up 13 seconds   0.0.0.0:6006->6006/tcp, :::6006->6006/tcp, 0.0.0.0:8888->8888/tcp, :::8888->8888/tcp   hfpt_Dec14   247GB (virtual 267GB)\n",
    "\n",
    "# Disk Usage Analyzer reports 769.5 GB used, 694071 items ...\n",
    "\n",
    "# Now let's torch all models in the /root/.cache/huggingface/hub folder, then see how much space you have ...\n",
    "\n",
    "# WTF!? Disk Usage Analyzer still shows the same usage!! \n",
    "# The below results seem correct! ... \n",
    "\n",
    "# (base) rob@KAUWITB:~$ docker ps --size\n",
    "# CONTAINER ID   IMAGE           COMMAND                  CREATED       STATUS          PORTS                                                                                  NAMES        SIZE\n",
    "# c8324b70601d   hfpt:20231214   \"/opt/nvidia/nvidia_…\"   3 weeks ago   Up 22 minutes   0.0.0.0:6006->6006/tcp, :::6006->6006/tcp, 0.0.0.0:8888->8888/tcp, :::8888->8888/tcp   hfpt_Dec14   26.3GB (virtual 46.9GB)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /root/.cache/huggingface/hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformersFolder = '/root/.cache/huggingface/datasets'\n",
    "\n",
    "# Total file size of all folders: 13,142,291,016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformersFolder = '/root/.cache/huggingface/modules'\n",
    "\n",
    "# Total file size of all folders: 558,776"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformersFolder = '/root/.cache/huggingface/token'\n",
    "# hmm can't scan this ...meh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/root/.cache/huggingface/hub': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# !ls /home/rob/Data2/huggingface/transformers\n",
    "!ls /root/.cache/huggingface/hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backup any model shown above that has not already been backed up to either '/home/rob/Data2/huggingface/transformers' or '/home/rob/Data3/huggingface/transformers'\n",
    "\n",
    "# docker cp c8324b70601d://root/.cache/huggingface/hub/models--dn118--unaestheticXL /home/rob/Data3/huggingface/transformers\n",
    "# Successfully copied 39.4kB to /home/rob/Data3/huggingface/transformers\n",
    "\n",
    "# docker cp c8324b70601d://root/.cache/huggingface/hub/models--kandinsky-community--kandinsky-2-2-prior /home/rob/Data3/huggingface/transformers\n",
    "# Successfully copied 10.6GB to /home/rob/Data3/huggingface/transformers\n",
    "\n",
    "# docker cp c8324b70601d://root/.cache/huggingface/hub/models--sd-concepts-library--cat-toy /home/rob/Data3/huggingface/transformers\n",
    "# Successfully copied 11.3kB to /home/rob/Data3/huggingface/transformers\n",
    "\n",
    "# docker cp c8324b70601d://root/.cache/huggingface/hub/models--stabilityai--stable-diffusion-xl-base-1.0 /home/rob/Data3/huggingface/transformers\n",
    "# Successfully copied 7.11GB to /home/rob/Data3/huggingface/transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below was generated by [chatgpt](https://chat.openai.com/c/857d7961-fd72-4019-bfc6-61600a67410b)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Subfolder sizes (sorted with commas):\n",
      "                                               Folder            Size\n",
      "73           2539ff53e6baa4cc603774ad5a2d646f4041ea4e  52,064,236,253\n",
      "19        models--mistralai--Mistral-7B-Instruct-v0.2  43,457,442,418\n",
      "27      models--TheBloke--CodeLlama-34B-Instruct-GPTQ  36,662,820,244\n",
      "5          models--teknium--OpenHermes-2.5-Mistral-7B  28,968,103,780\n",
      "76           0a2785d47fb7330388e0487e0526bbc53d87c156  18,331,410,102\n",
      "..                                                ...             ...\n",
      "29  models--stabilityai--stable-diffusion-xl-refin...               0\n",
      "30  models--stabilityai--stable-diffusion-xl-base-1.0               0\n",
      "31               models--nitrosocke--Ghibli-Diffusion               0\n",
      "1       models--lllyasviel--control_v11p_sd15_inpaint               0\n",
      "0                        models--google--ddpm-cat-256               0\n",
      "\n",
      "[82 rows x 2 columns]\n",
      "\n",
      "Total file size of all folders: 381,939,169,491\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def get_folder_size(folder_path):\n",
    "    total_size = 0\n",
    "\n",
    "    for dirpath, dirnames, filenames in os.walk(folder_path):\n",
    "        for filename in filenames:\n",
    "            file_path = os.path.join(dirpath, filename)\n",
    "            total_size += os.path.getsize(file_path)\n",
    "\n",
    "    return total_size\n",
    "\n",
    "def get_subfolder_sizes(parent_folder):\n",
    "    subfolder_sizes = {}\n",
    "\n",
    "    for dirpath, dirnames, _ in os.walk(parent_folder):\n",
    "        for dirname in dirnames:\n",
    "            folder_path = os.path.join(dirpath, dirname)\n",
    "            total_size = get_folder_size(folder_path)\n",
    "            subfolder_sizes[dirname] = total_size\n",
    "\n",
    "    return subfolder_sizes\n",
    "\n",
    "def format_size_with_commas(size):\n",
    "    return \"{:,}\".format(size)\n",
    "\n",
    "def main():\n",
    "    \n",
    "     # folder_path = input(\"Enter the folder path: \")\n",
    "    folder_path = transformersFolder\n",
    "\n",
    "    if not os.path.exists(folder_path) or not os.path.isdir(folder_path):\n",
    "        print(\"Invalid folder path. Please provide a valid folder path.\")\n",
    "        return\n",
    "\n",
    "    subfolder_sizes = get_subfolder_sizes(folder_path)\n",
    "\n",
    "    # Create a pandas DataFrame\n",
    "    df = pd.DataFrame(list(subfolder_sizes.items()), columns=['Folder', 'Size'])\n",
    "\n",
    "    # Convert the 'Size' column to integers for sorting\n",
    "    df['Size'] = df['Size'].astype(int)\n",
    "\n",
    "    # Sort the DataFrame by 'Size' in descending order\n",
    "    df = df.sort_values(by='Size', ascending=False)\n",
    "\n",
    "    # Format the 'Size' column with commas\n",
    "    df['Size'] = df['Size'].apply(format_size_with_commas)\n",
    "\n",
    "    # Calculate the total file size of all folders summed\n",
    "    total_size = df['Size'].str.replace(',', '', regex=True).astype(int).sum()\n",
    "    total_size_formatted = format_size_with_commas(total_size)\n",
    "\n",
    "    print(\"\\nSubfolder sizes (sorted with commas):\")\n",
    "    print(df)\n",
    "    print(f\"\\nTotal file size of all folders: {total_size_formatted}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gonna kill some stuff and see if it breaks anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models--bert-base-cased\n",
      "models--bigscience--bloomz-560m\n",
      "models--decapoda-research--llama-13b-hf\n",
      "models--facebook--bart-large-cnn\n",
      "models--google--pegasus-cnn_dailymail\n",
      "models--google--vit-base-patch16-224-in21k\n",
      "models--gpt2\n",
      "models--gpt2-xl\n",
      "models--meta-llama--Llama-2-13b-hf\n",
      "models--meta-llama--Llama-2-7b-chat-hf\n",
      "models--meta-llama--Llama-2-7b-hf\n",
      "models--mistralai--Mistral-7B-Instruct-v0.1\n",
      "models--mistralai--Mistral-7B-v0.1\n",
      "models--nvidia--mit-b0\n",
      "models--openai-gpt\n",
      "models--roberta-large\n",
      "models--robkayinto--vit-base-patch16-224-in21k-finetuned-lora-food101\n",
      "models--t5-large\n",
      "models--transformersbook--pegasus-samsum\n",
      "models--xlm-roberta-base\n",
      "tmp3i5avt2i\n",
      "tmp560c_s3e\n",
      "tmp8is86yg8\n",
      "tmpea0zbrrj\n",
      "tmplm91b70r\n",
      "tmpni3ccozw\n",
      "tmpo224crmi\n",
      "version.txt\n"
     ]
    }
   ],
   "source": [
    "# !ls /home/rob/Data2/huggingface/transformers\n",
    "!ls /root/.cache/huggingface/hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf /home/rob/Data2/huggingface/transformers/models--meta-llama--Llama-2-7b-chat-hf\n",
    "# docker cp /home/rob/Data2/huggingface/transformers/models--meta-llama--Llama-2-7b-chat-hf c9b676310ea0://home/rob/Data2/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (base) rob@KAUWITB:~$ docker cp c9b676310ea0://home/rob/Data2/huggingface/transformers/models--bert-base-cased  /home/rob/Data3/huggingface/transformers\n",
    "# Successfully copied 662kB to /home/rob/Data3/huggingface/transformers\n",
    "# (base) rob@KAUWITB:~$ docker cp c9b676310ea0://home/rob/Data2/huggingface/transformers/models--bigscience--bloomz-560m  /home/rob/Data3/huggingface/transformers\n",
    "# Successfully copied 1.13GB to /home/rob/Data3/huggingface/transformers\n",
    "# (base) rob@KAUWITB:~$ docker cp c9b676310ea0://home/rob/Data2/huggingface/transformers/models--decapoda-research--llama-13b-hf  /home/rob/Data3/huggingface/transformers\n",
    "# Successfully copied 1.54kB to /home/rob/Data3/huggingface/transformers\n",
    "# (base) rob@KAUWITB:~$ docker cp c9b676310ea0://home/rob/Data2/huggingface/transformers/models--facebook--bart-large-cnn  /home/rob/Data3/huggingface/transformers\n",
    "# Successfully copied 1.63GB to /home/rob/Data3/huggingface/transformers\n",
    "# (base) rob@KAUWITB:~$ docker cp c9b676310ea0://home/rob/Data2/huggingface/transformers/models--google--pegasus-cnn_dailymail  /home/rob/Data3/huggingface/transformers\n",
    "# Successfully copied 2.28GB to /home/rob/Data3/huggingface/transformers\n",
    "# (base) rob@KAUWITB:~$ docker cp c9b676310ea0://home/rob/Data2/huggingface/transformers/models--google--vit-base-patch16-224-in21k  /home/rob/Data3/huggingface/transformers\n",
    "# Successfully copied 346MB to /home/rob/Data3/huggingface/transformers\n",
    "# (base) rob@KAUWITB:~$ docker cp c9b676310ea0://home/rob/Data2/huggingface/transformers/models--gpt2  /home/rob/Data3/huggingface/transformers\n",
    "# Successfully copied 551MB to /home/rob/Data3/huggingface/transformers\n",
    "# (base) rob@KAUWITB:~$ docker cp c9b676310ea0://home/rob/Data2/huggingface/transformers/models--gpt2-xl  /home/rob/Data3/huggingface/transformers\n",
    "# Successfully copied 6.43GB to /home/rob/Data3/huggingface/transformers\n",
    "# (base) rob@KAUWITB:~$ docker cp c9b676310ea0://home/rob/Data2/huggingface/transformers/models--nvidia--mit-b0  /home/rob/Data3/huggingface/transformers\n",
    "# Successfully copied 14.5MB to /home/rob/Data3/huggingface/transformers\n",
    "# (base) rob@KAUWITB:~$ docker cp c9b676310ea0://home/rob/Data2/huggingface/transformers/models--openai-gpt  /home/rob/Data3/huggingface/transformers\n",
    "# Successfully copied 481MB to /home/rob/Data3/huggingface/transformers\n",
    "# (base) rob@KAUWITB:~$ docker cp c9b676310ea0://home/rob/Data2/huggingface/transformers/models--roberta-large  /home/rob/Data3/huggingface/transformers\n",
    "# Successfully copied 1.42GB to /home/rob/Data3/huggingface/transformers\n",
    "# (base) rob@KAUWITB:~$ docker cp c9b676310ea0://home/rob/Data2/huggingface/transformers/models--t5-large  /home/rob/Data3/huggingface/transformers\n",
    "# Successfully copied 2.95GB to /home/rob/Data3/huggingface/transformers\n",
    "# (base) rob@KAUWITB:~$ docker cp c9b676310ea0://home/rob/Data2/huggingface/transformers/models--transformersbook--pegasus-samsum  /home/rob/Data3/huggingface/transformers\n",
    "# Successfully copied 2.29GB to /home/rob/Data3/huggingface/transformers\n",
    "# (base) rob@KAUWITB:~$ docker cp c9b676310ea0://home/rob/Data2/huggingface/transformers/models--xlm-roberta-base  /home/rob/Data3/huggingface/transformers\n",
    "# Successfully copied 1.13GB to /home/rob/Data3/huggingface/transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data2 started with 290gb free ... then I started whacking these folders ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--bert-base-cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--bigscience--bloomz-560m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--decapoda-research--llama-13b-hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--facebook--bart-large-cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--google--pegasus-cnn_dailymail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--google--vit-base-patch16-224-in21k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--gpt2-xl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--nvidia--mit-b0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--openai-gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--roberta-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--t5-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--transformersbook--pegasus-samsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--xlm-roberta-base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, now let's see what we have ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models--meta-llama--Llama-2-13b-hf\n",
      "models--meta-llama--Llama-2-7b-chat-hf\n",
      "models--meta-llama--Llama-2-7b-hf\n",
      "models--mistralai--Mistral-7B-Instruct-v0.1\n",
      "models--mistralai--Mistral-7B-v0.1\n",
      "models--robkayinto--vit-base-patch16-224-in21k-finetuned-lora-food101\n",
      "tmp3i5avt2i\n",
      "tmp560c_s3e\n",
      "tmp8is86yg8\n",
      "tmpea0zbrrj\n",
      "tmplm91b70r\n",
      "tmpni3ccozw\n",
      "tmpo224crmi\n",
      "version.txt\n"
     ]
    }
   ],
   "source": [
    "!ls /home/rob/Data2/huggingface/transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK ... now we have 310gb free ... keep going ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--meta-llama--Llama-2-13b-hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--meta-llama--Llama-2-7b-chat-hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--meta-llama--Llama-2-7b-hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--mistralai--Mistral-7B-Instruct-v0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--mistralai--Mistral-7B-v0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, have another looksee ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models--robkayinto--vit-base-patch16-224-in21k-finetuned-lora-food101\n",
      "tmp3i5avt2i\n",
      "tmp560c_s3e\n",
      "tmp8is86yg8\n",
      "tmpea0zbrrj\n",
      "tmplm91b70r\n",
      "tmpni3ccozw\n",
      "tmpo224crmi\n",
      "version.txt\n"
     ]
    }
   ],
   "source": [
    "!ls /home/rob/Data2/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--robkayinto--vit-base-patch16-224-in21k-finetuned-lora-food101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp3i5avt2i  tmp8is86yg8  tmplm91b70r  tmpo224crmi\n",
      "tmp560c_s3e  tmpea0zbrrj  tmpni3ccozw  version.txt\n"
     ]
    }
   ],
   "source": [
    "!ls /home/rob/Data2/huggingface/transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK ... there is now 393gb free ... ok, thats good enough for now ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
