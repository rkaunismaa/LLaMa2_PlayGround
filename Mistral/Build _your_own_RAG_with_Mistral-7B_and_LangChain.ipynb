{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thursday, December 14, 2023\n",
    "\n",
    "Gonna give this another go, to see if things now magically work ...\n",
    "\n",
    "I manually created this notebook from the medium blog post, but I just saw the author DOES include a [notebook link](https://github.com/madhavthaker1/llm/blob/main/rag/e2e_rag.ipynb) ... and the blog post does NOT show all of the code. I added in the missing code, and now this all runs! Nice!\n",
    "\n",
    "### Thursday, November 30, 2023\n",
    "\n",
    "Attempting to run this again ...\n",
    "\n",
    "docker container start hfpt_Oct28\n",
    "\n",
    "### Sunday, November 26, 2023\n",
    "\n",
    "[Build your own RAG with Mistral-7B and LangChain](https://medium.com/@thakermadhav/build-your-own-rag-with-mistral-7b-and-langchain-97d0c92fa146)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q torch datasets\n",
    "# !pip install -q accelerate==0.21.0 peft==0.4.0 bitsandbytes==0.40.2 transformers==4.31.0 trl==0.4.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    pipeline\n",
    ")\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, PeftModel\n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_transformers import Html2TextTransformer\n",
    "from langchain.document_loaders import AsyncChromiumLoader\n",
    "\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models--mistralai--Mistral-7B-Instruct-v0.1  tmp0m77pc0x  tmpidgz7up0\n",
      "models--mistralai--Mistral-7B-v0.1\t     tmpc719_es2  tmpm3p4mg9v\n",
      "models--model_name\t\t\t     tmpcjh0h7gn  tmpz6ieywz4\n",
      "models--teknium--OpenHermes-2.5-Mistral-7B   tmpczxu4e1z  tmpzafytbf_\n",
      "tmp05dbfcvi\t\t\t\t     tmpfcrmwgx2  version.txt\n"
     ]
    }
   ],
   "source": [
    "!ls /home/rob/Data2/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models--mistralai--Mistral-7B-Instruct-v0.1  tmp0m77pc0x  tmpidgz7up0\n",
      "models--mistralai--Mistral-7B-v0.1\t     tmpc719_es2  tmpm3p4mg9v\n",
      "models--model_name\t\t\t     tmpcjh0h7gn  tmpz6ieywz4\n",
      "models--teknium--OpenHermes-2.5-Mistral-7B   tmpczxu4e1z  tmpzafytbf_\n",
      "tmp05dbfcvi\t\t\t\t     tmpfcrmwgx2  version.txt\n"
     ]
    }
   ],
   "source": [
    "# docker cp /home/rob/Data3/huggingface/transformers/models--mistralai--Mistral-7B-Instruct-v0.1 c9b676310ea0://home/rob/Data2/huggingface/transformers\n",
    "# Successfully copied 14.5GB to c9b676310ea0://home/rob/Data2/huggingface/transformers\n",
    "!ls /home/rob/Data2/huggingface/transformers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "model_name='mistralai/Mistral-7B-Instruct-v0.1'\n",
    "\n",
    "model_config = transformers.AutoConfig.from_pretrained(\n",
    "    model_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bits and Bytes parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate 4-bit precision base model loading\n",
    "use_4bit = True\n",
    "\n",
    "# Compute dtype for 4-bit base models\n",
    "bnb_4bit_compute_dtype = \"float16\"\n",
    "\n",
    "# Quantization type (fp4 or nf4)\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "\n",
    "# Activate nested quantization for 4-bit base models (double quantization)\n",
    "use_nested_quant = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up quantization config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=use_4bit,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=use_nested_quant,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Your GPU supports bfloat16: accelerate training with bf16=True\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Check GPU compatibility with bfloat16\n",
    "if compute_dtype == torch.float16 and use_4bit:\n",
    "    major, _ = torch.cuda.get_device_capability()\n",
    "    if major >= 8:\n",
    "        print(\"=\" * 80)\n",
    "        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n",
    "        print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pre-trained config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d88bd382d3f464f9716ac2040645c4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    ")\n",
    "\n",
    "# 15.3s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count number of trainable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_number_of_trainable_model_parameters(model):\n",
    "    trainable_model_params = 0\n",
    "    all_model_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable model parameters: 262410240\n",
      "all model parameters: 3752071168\n",
      "percentage of trainable model parameters: 6.99%\n"
     ]
    }
   ],
   "source": [
    "print(print_number_of_trainable_model_parameters(model))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Mistral text generation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generation_pipeline = transformers.pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    task=\"text-generation\",\n",
    "    temperature=0.2,\n",
    "    repetition_penalty=1.1,\n",
    "    return_full_text=True,\n",
    "    max_new_tokens=1000,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistral_llm = HuggingFacePipeline(pipeline=text_generation_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and chunk documents. Load chunked documents into FAISS index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Articles to index\n",
    "articles = [\"https://www.fantasypros.com/2023/11/rival-fantasy-nfl-week-10/\",\n",
    "            \"https://www.fantasypros.com/2023/11/5-stats-to-know-before-setting-your-fantasy-lineup-week-10/\",\n",
    "            \"https://www.fantasypros.com/2023/11/nfl-week-10-sleeper-picks-player-predictions-2023/\",\n",
    "            \"https://www.fantasypros.com/2023/11/nfl-dfs-week-10-stacking-advice-picks-2023-fantasy-football/\",\n",
    "            \"https://www.fantasypros.com/2023/11/players-to-buy-low-sell-high-trade-advice-2023-fantasy-football/\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Firing this for the first time produced an error ...\n",
    "# ImportError: playwright is required for AsyncChromiumLoader. Please install it with `pip install playwright`.\n",
    "# pip install playwright\n",
    "\n",
    "\n",
    "# Scrapes the blogs above\n",
    "loader = AsyncChromiumLoader(articles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This does not run ... sigh.\n",
    "# The error message suggests running the following command from the terminal\n",
    "# playwright install-deps\n",
    "# I did this and it appeared to install a ton of stuff ...\n",
    "# OK Nice! This now runs!\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "# 1m 41.0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running this for the first time generates an error ... solution is to ..\n",
    "# pip install html2text\n",
    "\n",
    "# Converts HTML to plain text \n",
    "html2text = Html2TextTransformer()\n",
    "docs_transformed = html2text.transform_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 146, which is longer than the specified 100\n",
      "Created a chunk of size 4148, which is longer than the specified 100\n",
      "Created a chunk of size 567, which is longer than the specified 100\n",
      "Created a chunk of size 316, which is longer than the specified 100\n",
      "Created a chunk of size 136, which is longer than the specified 100\n",
      "Created a chunk of size 249, which is longer than the specified 100\n",
      "Created a chunk of size 113, which is longer than the specified 100\n",
      "Created a chunk of size 449, which is longer than the specified 100\n",
      "Created a chunk of size 137, which is longer than the specified 100\n",
      "Created a chunk of size 201, which is longer than the specified 100\n",
      "Created a chunk of size 132, which is longer than the specified 100\n",
      "Created a chunk of size 479, which is longer than the specified 100\n",
      "Created a chunk of size 216, which is longer than the specified 100\n",
      "Created a chunk of size 138, which is longer than the specified 100\n",
      "Created a chunk of size 172, which is longer than the specified 100\n",
      "Created a chunk of size 183, which is longer than the specified 100\n",
      "Created a chunk of size 140, which is longer than the specified 100\n",
      "Created a chunk of size 180, which is longer than the specified 100\n",
      "Created a chunk of size 118, which is longer than the specified 100\n",
      "Created a chunk of size 114, which is longer than the specified 100\n",
      "Created a chunk of size 194, which is longer than the specified 100\n",
      "Created a chunk of size 533, which is longer than the specified 100\n",
      "Created a chunk of size 446, which is longer than the specified 100\n",
      "Created a chunk of size 141, which is longer than the specified 100\n",
      "Created a chunk of size 120, which is longer than the specified 100\n",
      "Created a chunk of size 317, which is longer than the specified 100\n",
      "Created a chunk of size 115, which is longer than the specified 100\n",
      "Created a chunk of size 142, which is longer than the specified 100\n",
      "Created a chunk of size 111, which is longer than the specified 100\n",
      "Created a chunk of size 232, which is longer than the specified 100\n",
      "Created a chunk of size 118, which is longer than the specified 100\n",
      "Created a chunk of size 142, which is longer than the specified 100\n",
      "Created a chunk of size 101, which is longer than the specified 100\n",
      "Created a chunk of size 293, which is longer than the specified 100\n",
      "Created a chunk of size 146, which is longer than the specified 100\n",
      "Created a chunk of size 4148, which is longer than the specified 100\n",
      "Created a chunk of size 450, which is longer than the specified 100\n",
      "Created a chunk of size 125, which is longer than the specified 100\n",
      "Created a chunk of size 133, which is longer than the specified 100\n",
      "Created a chunk of size 462, which is longer than the specified 100\n",
      "Created a chunk of size 178, which is longer than the specified 100\n",
      "Created a chunk of size 469, which is longer than the specified 100\n",
      "Created a chunk of size 432, which is longer than the specified 100\n",
      "Created a chunk of size 380, which is longer than the specified 100\n",
      "Created a chunk of size 105, which is longer than the specified 100\n",
      "Created a chunk of size 134, which is longer than the specified 100\n",
      "Created a chunk of size 132, which is longer than the specified 100\n",
      "Created a chunk of size 115, which is longer than the specified 100\n",
      "Created a chunk of size 111, which is longer than the specified 100\n",
      "Created a chunk of size 232, which is longer than the specified 100\n",
      "Created a chunk of size 118, which is longer than the specified 100\n",
      "Created a chunk of size 142, which is longer than the specified 100\n",
      "Created a chunk of size 101, which is longer than the specified 100\n",
      "Created a chunk of size 293, which is longer than the specified 100\n",
      "Created a chunk of size 146, which is longer than the specified 100\n",
      "Created a chunk of size 4148, which is longer than the specified 100\n",
      "Created a chunk of size 178, which is longer than the specified 100\n",
      "Created a chunk of size 422, which is longer than the specified 100\n",
      "Created a chunk of size 282, which is longer than the specified 100\n",
      "Created a chunk of size 498, which is longer than the specified 100\n",
      "Created a chunk of size 164, which is longer than the specified 100\n",
      "Created a chunk of size 413, which is longer than the specified 100\n",
      "Created a chunk of size 242, which is longer than the specified 100\n",
      "Created a chunk of size 203, which is longer than the specified 100\n",
      "Created a chunk of size 456, which is longer than the specified 100\n",
      "Created a chunk of size 404, which is longer than the specified 100\n",
      "Created a chunk of size 145, which is longer than the specified 100\n",
      "Created a chunk of size 127, which is longer than the specified 100\n",
      "Created a chunk of size 232, which is longer than the specified 100\n",
      "Created a chunk of size 139, which is longer than the specified 100\n",
      "Created a chunk of size 221, which is longer than the specified 100\n",
      "Created a chunk of size 154, which is longer than the specified 100\n",
      "Created a chunk of size 121, which is longer than the specified 100\n",
      "Created a chunk of size 380, which is longer than the specified 100\n",
      "Created a chunk of size 234, which is longer than the specified 100\n",
      "Created a chunk of size 123, which is longer than the specified 100\n",
      "Created a chunk of size 230, which is longer than the specified 100\n",
      "Created a chunk of size 346, which is longer than the specified 100\n",
      "Created a chunk of size 115, which is longer than the specified 100\n",
      "Created a chunk of size 142, which is longer than the specified 100\n",
      "Created a chunk of size 111, which is longer than the specified 100\n",
      "Created a chunk of size 232, which is longer than the specified 100\n",
      "Created a chunk of size 118, which is longer than the specified 100\n",
      "Created a chunk of size 142, which is longer than the specified 100\n",
      "Created a chunk of size 101, which is longer than the specified 100\n",
      "Created a chunk of size 293, which is longer than the specified 100\n",
      "Created a chunk of size 146, which is longer than the specified 100\n",
      "Created a chunk of size 4148, which is longer than the specified 100\n",
      "Created a chunk of size 403, which is longer than the specified 100\n",
      "Created a chunk of size 146, which is longer than the specified 100\n",
      "Created a chunk of size 136, which is longer than the specified 100\n",
      "Created a chunk of size 267, which is longer than the specified 100\n",
      "Created a chunk of size 203, which is longer than the specified 100\n",
      "Created a chunk of size 541, which is longer than the specified 100\n",
      "Created a chunk of size 120, which is longer than the specified 100\n",
      "Created a chunk of size 300, which is longer than the specified 100\n",
      "Created a chunk of size 324, which is longer than the specified 100\n",
      "Created a chunk of size 281, which is longer than the specified 100\n",
      "Created a chunk of size 305, which is longer than the specified 100\n",
      "Created a chunk of size 333, which is longer than the specified 100\n",
      "Created a chunk of size 457, which is longer than the specified 100\n",
      "Created a chunk of size 421, which is longer than the specified 100\n",
      "Created a chunk of size 528, which is longer than the specified 100\n",
      "Created a chunk of size 154, which is longer than the specified 100\n",
      "Created a chunk of size 592, which is longer than the specified 100\n",
      "Created a chunk of size 633, which is longer than the specified 100\n",
      "Created a chunk of size 128, which is longer than the specified 100\n",
      "Created a chunk of size 235, which is longer than the specified 100\n",
      "Created a chunk of size 303, which is longer than the specified 100\n",
      "Created a chunk of size 658, which is longer than the specified 100\n",
      "Created a chunk of size 155, which is longer than the specified 100\n",
      "Created a chunk of size 236, which is longer than the specified 100\n",
      "Created a chunk of size 520, which is longer than the specified 100\n",
      "Created a chunk of size 172, which is longer than the specified 100\n",
      "Created a chunk of size 162, which is longer than the specified 100\n",
      "Created a chunk of size 438, which is longer than the specified 100\n",
      "Created a chunk of size 333, which is longer than the specified 100\n",
      "Created a chunk of size 581, which is longer than the specified 100\n",
      "Created a chunk of size 183, which is longer than the specified 100\n",
      "Created a chunk of size 432, which is longer than the specified 100\n",
      "Created a chunk of size 208, which is longer than the specified 100\n",
      "Created a chunk of size 242, which is longer than the specified 100\n",
      "Created a chunk of size 574, which is longer than the specified 100\n",
      "Created a chunk of size 204, which is longer than the specified 100\n",
      "Created a chunk of size 105, which is longer than the specified 100\n",
      "Created a chunk of size 741, which is longer than the specified 100\n",
      "Created a chunk of size 115, which is longer than the specified 100\n",
      "Created a chunk of size 111, which is longer than the specified 100\n",
      "Created a chunk of size 232, which is longer than the specified 100\n",
      "Created a chunk of size 118, which is longer than the specified 100\n",
      "Created a chunk of size 142, which is longer than the specified 100\n",
      "Created a chunk of size 101, which is longer than the specified 100\n",
      "Created a chunk of size 293, which is longer than the specified 100\n"
     ]
    }
   ],
   "source": [
    "# Chunk text\n",
    "text_splitter = CharacterTextSplitter(chunk_size=100, \n",
    "                                      chunk_overlap=0)\n",
    "chunked_documents = text_splitter.split_documents(docs_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load chunked documents into the FAISS index\n",
    "db = FAISS.from_documents(chunked_documents, \n",
    "                          HuggingFaceEmbeddings(model_name='sentence-transformers/all-mpnet-base-v2'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create PromptTemplate and LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "### [INST] Instruction: Answer the question based on your fantasy football knowledge. Here is context to help:\n",
    "\n",
    "{context}\n",
    "\n",
    "### QUESTION:\n",
    "{question} [/INST]\n",
    " \"\"\"\n",
    "\n",
    "# Create prompt from prompt template \n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=prompt_template,\n",
    ")\n",
    "\n",
    "# Create llm chain \n",
    "llm_chain = LLMChain(llm=mistral_llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = ( \n",
    " {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | llm_chain\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'context': [Document(page_content='This week, Harris faces the bottom-of-the-barrel Packers’ run defense that\\nallows the ninth-most fantasy points per game to the running back position.\\nHarris will give you a higher-volume RB with a low rostership percentage this\\nweek.', metadata={'source': 'https://www.fantasypros.com/2023/11/nfl-dfs-week-10-stacking-advice-picks-2023-fantasy-football/'}),\n",
       "  Document(page_content='could start cutting into his workload. Furthermore, his rest of the season\\nschedule isn’t fantasy-friendly. Try to flip Edwards and a WR3 for Kenneth\\nWalker or Tony Pollard', metadata={'source': 'https://www.fantasypros.com/2023/11/players-to-buy-low-sell-high-trade-advice-2023-fantasy-football/'}),\n",
       "  Document(page_content='“ **Gus Edwards** has been on fire lately. He is the RB1 over the past three\\nweeks, averaging 22.2 half-point PPR fantasy points and two rushing touchdowns\\nper game. However, over 54% of his fantasy production came from the six\\nrushing touchdowns. Meanwhile, the veteran averaged only 6.5 fantasy points\\nper game over the first six contests. He had more than six fantasy points only\\nonce, in the Week 2 matchup where Edwards found the end zone. The veteran\\nrunning back is a touchdown-or-bust player, and Keaton Mitchell', metadata={'source': 'https://www.fantasypros.com/2023/11/players-to-buy-low-sell-high-trade-advice-2023-fantasy-football/'}),\n",
       "  Document(page_content='Remember to read all the fantastic work here at FantasyPros and reach out on\\nTwitter at @jpep20 if you need extra help. Good luck in Week 10!', metadata={'source': 'https://www.fantasypros.com/2023/11/5-stats-to-know-before-setting-your-fantasy-lineup-week-10/'})],\n",
       " 'question': 'Should I start Gibbs next week for fantasy?',\n",
       " 'text': ' Based on the information provided, it seems like Gus Edwards has been performing well recently and could be a good option to consider starting next week. However, it\\'s important to keep in mind that he has a high volume of production coming from rushing touchdowns, which can make him a bit of a \"touchdown-or-bust\" player. Additionally, his schedule for the rest of the season may not be as favorable for fantasy purposes. It might be worth considering flipping him for another running back or wide receiver who has a better schedule or a lower rostership percentage. Ultimately, the decision to start Gibbs next week should be based on your specific team needs and other factors such as injuries or trades.'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"Should I start Gibbs next week for fantasy?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
