{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thursday, November 9, 2023\n",
    "\n",
    "Determine the size of the models in the transformers folder. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformersFolder = '/home/rob/Data2/huggingface/transformers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models--bert-base-cased\n",
      "models--bigscience--bloomz-560m\n",
      "models--decapoda-research--llama-13b-hf\n",
      "models--facebook--bart-large-cnn\n",
      "models--google--pegasus-cnn_dailymail\n",
      "models--google--vit-base-patch16-224-in21k\n",
      "models--gpt2\n",
      "models--gpt2-xl\n",
      "models--meta-llama--Llama-2-13b-hf\n",
      "models--meta-llama--Llama-2-7b-chat-hf\n",
      "models--meta-llama--Llama-2-7b-hf\n",
      "models--mistralai--Mistral-7B-Instruct-v0.1\n",
      "models--mistralai--Mistral-7B-v0.1\n",
      "models--nvidia--mit-b0\n",
      "models--openai-gpt\n",
      "models--roberta-large\n",
      "models--robkayinto--vit-base-patch16-224-in21k-finetuned-lora-food101\n",
      "models--t5-large\n",
      "models--transformersbook--pegasus-samsum\n",
      "models--xlm-roberta-base\n",
      "tmp3i5avt2i\n",
      "tmp560c_s3e\n",
      "tmp8is86yg8\n",
      "tmpea0zbrrj\n",
      "tmplm91b70r\n",
      "tmpni3ccozw\n",
      "tmpo224crmi\n",
      "version.txt\n"
     ]
    }
   ],
   "source": [
    "!ls /home/rob/Data2/huggingface/transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below was generated by [chatgpt](https://chat.openai.com/c/857d7961-fd72-4019-bfc6-61600a67410b)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Subfolder sizes (sorted with commas):\n",
      "                                               Folder            Size\n",
      "14                 models--meta-llama--Llama-2-13b-hf  52,068,325,708\n",
      "16        models--mistralai--Mistral-7B-Instruct-v0.1  30,020,333,288\n",
      "5                  models--mistralai--Mistral-7B-v0.1  30,020,332,288\n",
      "13                  models--meta-llama--Llama-2-7b-hf  26,958,495,114\n",
      "36           99afe33d7eaa87c7fc6ea2594a0e4e7e588ee0a4  26,034,162,834\n",
      "38           7ad5799710574ba1c1d953eba3077af582f3a773  15,010,166,624\n",
      "27           5e9c98b96d071dce59368012254c55b0ec6f8658  15,010,166,124\n",
      "35           6fdf2e60f86ff2481f2241aaee459f85b5b0bbb9  13,479,247,537\n",
      "4                                     models--gpt2-xl  12,869,369,344\n",
      "26           b81cf803a4e4e809062586ac620a06e65d9e20b6   6,434,684,652\n",
      "12                                   models--t5-large   5,905,838,230\n",
      "15           models--transformersbook--pegasus-samsum   4,571,485,508\n",
      "6               models--google--pegasus-cnn_dailymail   4,554,483,970\n",
      "1                    models--facebook--bart-large-cnn   3,255,967,474\n",
      "34           150ebc2c4b72291e770f58e6057481c8d2ed331a   2,952,919,095\n",
      "8                               models--roberta-large   2,848,823,970\n",
      "37           f00170164d55821831b9396cc3da176af59f30ec   2,285,742,734\n",
      "28           40d588fdab0cc077b80d950b300bf66ad3c75b92   2,277,241,965\n",
      "7                     models--bigscience--bloomz-560m   2,265,921,860\n",
      "10                           models--xlm-roberta-base   2,259,468,112\n",
      "24           deb0f97cf6acb4f0a691356ed00ea06bf7e86e8f   1,627,983,717\n",
      "30           716877d372b884cad6d419d828bac6c85b3b18d9   1,424,411,965\n",
      "29           a2845d7e13dd12efae154a9f1c63fcc2e0cc4b05   1,132,960,910\n",
      "32           77de1f7a7e5e737aead1cd880979d4f1b3af6668   1,129,734,036\n",
      "9                                        models--gpt2   1,101,919,710\n",
      "0                                  models--openai-gpt     962,568,084\n",
      "2          models--google--vit-base-patch16-224-in21k     691,274,290\n",
      "31           11c5a3d5811f50298f278a704980280950aedb10     550,959,835\n",
      "23           adacbec1426c790163037629ab537b20464a8f71     481,284,022\n",
      "25           7cbdb7ee3a6bcdf99dae654893f66519c480a0f8     345,637,125\n",
      "11                             models--nvidia--mit-b0      28,900,728\n",
      "33           ed0b85c75627eab6a3c6989627450cf95f115381      14,450,344\n",
      "17                            models--bert-base-cased       1,299,732\n",
      "39           5532cc56f74641d4bb33641f5c76a55d11f846e0         649,846\n",
      "18  models--robkayinto--vit-base-patch16-224-in21k...             690\n",
      "20                                              blobs             325\n",
      "22                                          snapshots             325\n",
      "40           c8c4af8adf436c2b573bdc3150813e9e2e215b9b             325\n",
      "19                                               refs              40\n",
      "21                                          .no_exist               0\n",
      "3             models--decapoda-research--llama-13b-hf               0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def get_folder_size(folder_path):\n",
    "    total_size = 0\n",
    "\n",
    "    for dirpath, dirnames, filenames in os.walk(folder_path):\n",
    "        for filename in filenames:\n",
    "            file_path = os.path.join(dirpath, filename)\n",
    "            total_size += os.path.getsize(file_path)\n",
    "\n",
    "    return total_size\n",
    "\n",
    "def get_subfolder_sizes(parent_folder):\n",
    "    subfolder_sizes = {}\n",
    "\n",
    "    for dirpath, dirnames, _ in os.walk(parent_folder):\n",
    "        for dirname in dirnames:\n",
    "            folder_path = os.path.join(dirpath, dirname)\n",
    "            total_size = get_folder_size(folder_path)\n",
    "            subfolder_sizes[dirname] = total_size\n",
    "\n",
    "    return subfolder_sizes\n",
    "\n",
    "def format_size_with_commas(size):\n",
    "    return \"{:,}\".format(size)\n",
    "\n",
    "def main():\n",
    "\n",
    "    # folder_path = input(\"Enter the folder path: \")\n",
    "    folder_path = transformersFolder\n",
    "\n",
    "    if not os.path.exists(folder_path) or not os.path.isdir(folder_path):\n",
    "        print(\"Invalid folder path. Please provide a valid folder path.\")\n",
    "        return\n",
    "\n",
    "    subfolder_sizes = get_subfolder_sizes(folder_path)\n",
    "\n",
    "    # Create a pandas DataFrame\n",
    "    df = pd.DataFrame(list(subfolder_sizes.items()), columns=['Folder', 'Size'])\n",
    "\n",
    "    # Convert the 'Size' column to integers for sorting\n",
    "    df['Size'] = df['Size'].astype(int)\n",
    "\n",
    "    # Sort the DataFrame by 'Size' in descending order\n",
    "    df = df.sort_values(by='Size', ascending=False)\n",
    "\n",
    "    # Format the 'Size' column with commas\n",
    "    df['Size'] = df['Size'].apply(format_size_with_commas)\n",
    "\n",
    "    print(\"\\nSubfolder sizes (sorted with commas):\")\n",
    "    print(df)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Subfolder sizes (sorted with commas):\n",
      "                                               Folder            Size\n",
      "3                  models--meta-llama--Llama-2-13b-hf  52,068,325,708\n",
      "4         models--mistralai--Mistral-7B-Instruct-v0.1  30,020,333,288\n",
      "0                  models--mistralai--Mistral-7B-v0.1  30,020,332,288\n",
      "2                   models--meta-llama--Llama-2-7b-hf  26,958,495,114\n",
      "1              models--meta-llama--Llama-2-7b-chat-hf  26,958,489,416\n",
      "13           99afe33d7eaa87c7fc6ea2594a0e4e7e588ee0a4  26,034,162,834\n",
      "14           7ad5799710574ba1c1d953eba3077af582f3a773  15,010,166,624\n",
      "10           5e9c98b96d071dce59368012254c55b0ec6f8658  15,010,166,124\n",
      "12           6fdf2e60f86ff2481f2241aaee459f85b5b0bbb9  13,479,247,537\n",
      "11           94b07a6e30c3292b8265ed32ffdeccfdadf434a8  13,479,244,688\n",
      "5   models--robkayinto--vit-base-patch16-224-in21k...             690\n",
      "7                                               blobs             325\n",
      "9                                           snapshots             325\n",
      "15           c8c4af8adf436c2b573bdc3150813e9e2e215b9b             325\n",
      "6                                                refs              40\n",
      "8                                           .no_exist               0\n",
      "\n",
      "Total file size of all folders: 249,038,965,326\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def get_folder_size(folder_path):\n",
    "    total_size = 0\n",
    "\n",
    "    for dirpath, dirnames, filenames in os.walk(folder_path):\n",
    "        for filename in filenames:\n",
    "            file_path = os.path.join(dirpath, filename)\n",
    "            total_size += os.path.getsize(file_path)\n",
    "\n",
    "    return total_size\n",
    "\n",
    "def get_subfolder_sizes(parent_folder):\n",
    "    subfolder_sizes = {}\n",
    "\n",
    "    for dirpath, dirnames, _ in os.walk(parent_folder):\n",
    "        for dirname in dirnames:\n",
    "            folder_path = os.path.join(dirpath, dirname)\n",
    "            total_size = get_folder_size(folder_path)\n",
    "            subfolder_sizes[dirname] = total_size\n",
    "\n",
    "    return subfolder_sizes\n",
    "\n",
    "def format_size_with_commas(size):\n",
    "    return \"{:,}\".format(size)\n",
    "\n",
    "def main():\n",
    "    \n",
    "     # folder_path = input(\"Enter the folder path: \")\n",
    "    folder_path = transformersFolder\n",
    "\n",
    "    if not os.path.exists(folder_path) or not os.path.isdir(folder_path):\n",
    "        print(\"Invalid folder path. Please provide a valid folder path.\")\n",
    "        return\n",
    "\n",
    "    subfolder_sizes = get_subfolder_sizes(folder_path)\n",
    "\n",
    "    # Create a pandas DataFrame\n",
    "    df = pd.DataFrame(list(subfolder_sizes.items()), columns=['Folder', 'Size'])\n",
    "\n",
    "    # Convert the 'Size' column to integers for sorting\n",
    "    df['Size'] = df['Size'].astype(int)\n",
    "\n",
    "    # Sort the DataFrame by 'Size' in descending order\n",
    "    df = df.sort_values(by='Size', ascending=False)\n",
    "\n",
    "    # Format the 'Size' column with commas\n",
    "    df['Size'] = df['Size'].apply(format_size_with_commas)\n",
    "\n",
    "    # Calculate the total file size of all folders summed\n",
    "    total_size = df['Size'].str.replace(',', '', regex=True).astype(int).sum()\n",
    "    total_size_formatted = format_size_with_commas(total_size)\n",
    "\n",
    "    print(\"\\nSubfolder sizes (sorted with commas):\")\n",
    "    print(df)\n",
    "    print(f\"\\nTotal file size of all folders: {total_size_formatted}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gonna kill some stuff and see if it breaks anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models--bert-base-cased\n",
      "models--bigscience--bloomz-560m\n",
      "models--decapoda-research--llama-13b-hf\n",
      "models--facebook--bart-large-cnn\n",
      "models--google--pegasus-cnn_dailymail\n",
      "models--google--vit-base-patch16-224-in21k\n",
      "models--gpt2\n",
      "models--gpt2-xl\n",
      "models--meta-llama--Llama-2-13b-hf\n",
      "models--meta-llama--Llama-2-7b-chat-hf\n",
      "models--meta-llama--Llama-2-7b-hf\n",
      "models--mistralai--Mistral-7B-Instruct-v0.1\n",
      "models--mistralai--Mistral-7B-v0.1\n",
      "models--nvidia--mit-b0\n",
      "models--openai-gpt\n",
      "models--roberta-large\n",
      "models--robkayinto--vit-base-patch16-224-in21k-finetuned-lora-food101\n",
      "models--t5-large\n",
      "models--transformersbook--pegasus-samsum\n",
      "models--xlm-roberta-base\n",
      "tmp3i5avt2i\n",
      "tmp560c_s3e\n",
      "tmp8is86yg8\n",
      "tmpea0zbrrj\n",
      "tmplm91b70r\n",
      "tmpni3ccozw\n",
      "tmpo224crmi\n",
      "version.txt\n"
     ]
    }
   ],
   "source": [
    "!ls /home/rob/Data2/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf /home/rob/Data2/huggingface/transformers/models--meta-llama--Llama-2-7b-chat-hf\n",
    "# docker cp /home/rob/Data2/huggingface/transformers/models--meta-llama--Llama-2-7b-chat-hf c9b676310ea0://home/rob/Data2/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (base) rob@KAUWITB:~$ docker cp c9b676310ea0://home/rob/Data2/huggingface/transformers/models--bert-base-cased  /home/rob/Data3/huggingface/transformers\n",
    "# Successfully copied 662kB to /home/rob/Data3/huggingface/transformers\n",
    "# (base) rob@KAUWITB:~$ docker cp c9b676310ea0://home/rob/Data2/huggingface/transformers/models--bigscience--bloomz-560m  /home/rob/Data3/huggingface/transformers\n",
    "# Successfully copied 1.13GB to /home/rob/Data3/huggingface/transformers\n",
    "# (base) rob@KAUWITB:~$ docker cp c9b676310ea0://home/rob/Data2/huggingface/transformers/models--decapoda-research--llama-13b-hf  /home/rob/Data3/huggingface/transformers\n",
    "# Successfully copied 1.54kB to /home/rob/Data3/huggingface/transformers\n",
    "# (base) rob@KAUWITB:~$ docker cp c9b676310ea0://home/rob/Data2/huggingface/transformers/models--facebook--bart-large-cnn  /home/rob/Data3/huggingface/transformers\n",
    "# Successfully copied 1.63GB to /home/rob/Data3/huggingface/transformers\n",
    "# (base) rob@KAUWITB:~$ docker cp c9b676310ea0://home/rob/Data2/huggingface/transformers/models--google--pegasus-cnn_dailymail  /home/rob/Data3/huggingface/transformers\n",
    "# Successfully copied 2.28GB to /home/rob/Data3/huggingface/transformers\n",
    "# (base) rob@KAUWITB:~$ docker cp c9b676310ea0://home/rob/Data2/huggingface/transformers/models--google--vit-base-patch16-224-in21k  /home/rob/Data3/huggingface/transformers\n",
    "# Successfully copied 346MB to /home/rob/Data3/huggingface/transformers\n",
    "# (base) rob@KAUWITB:~$ docker cp c9b676310ea0://home/rob/Data2/huggingface/transformers/models--gpt2  /home/rob/Data3/huggingface/transformers\n",
    "# Successfully copied 551MB to /home/rob/Data3/huggingface/transformers\n",
    "# (base) rob@KAUWITB:~$ docker cp c9b676310ea0://home/rob/Data2/huggingface/transformers/models--gpt2-xl  /home/rob/Data3/huggingface/transformers\n",
    "# Successfully copied 6.43GB to /home/rob/Data3/huggingface/transformers\n",
    "# (base) rob@KAUWITB:~$ docker cp c9b676310ea0://home/rob/Data2/huggingface/transformers/models--nvidia--mit-b0  /home/rob/Data3/huggingface/transformers\n",
    "# Successfully copied 14.5MB to /home/rob/Data3/huggingface/transformers\n",
    "# (base) rob@KAUWITB:~$ docker cp c9b676310ea0://home/rob/Data2/huggingface/transformers/models--openai-gpt  /home/rob/Data3/huggingface/transformers\n",
    "# Successfully copied 481MB to /home/rob/Data3/huggingface/transformers\n",
    "# (base) rob@KAUWITB:~$ docker cp c9b676310ea0://home/rob/Data2/huggingface/transformers/models--roberta-large  /home/rob/Data3/huggingface/transformers\n",
    "# Successfully copied 1.42GB to /home/rob/Data3/huggingface/transformers\n",
    "# (base) rob@KAUWITB:~$ docker cp c9b676310ea0://home/rob/Data2/huggingface/transformers/models--t5-large  /home/rob/Data3/huggingface/transformers\n",
    "# Successfully copied 2.95GB to /home/rob/Data3/huggingface/transformers\n",
    "# (base) rob@KAUWITB:~$ docker cp c9b676310ea0://home/rob/Data2/huggingface/transformers/models--transformersbook--pegasus-samsum  /home/rob/Data3/huggingface/transformers\n",
    "# Successfully copied 2.29GB to /home/rob/Data3/huggingface/transformers\n",
    "# (base) rob@KAUWITB:~$ docker cp c9b676310ea0://home/rob/Data2/huggingface/transformers/models--xlm-roberta-base  /home/rob/Data3/huggingface/transformers\n",
    "# Successfully copied 1.13GB to /home/rob/Data3/huggingface/transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data2 started with 290gb free ... then I started whacking these folders ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--bert-base-cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--bigscience--bloomz-560m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--decapoda-research--llama-13b-hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--facebook--bart-large-cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--google--pegasus-cnn_dailymail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--google--vit-base-patch16-224-in21k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--gpt2-xl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--nvidia--mit-b0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--openai-gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--roberta-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--t5-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--transformersbook--pegasus-samsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--xlm-roberta-base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, now let's see what we have ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models--meta-llama--Llama-2-13b-hf\n",
      "models--meta-llama--Llama-2-7b-chat-hf\n",
      "models--meta-llama--Llama-2-7b-hf\n",
      "models--mistralai--Mistral-7B-Instruct-v0.1\n",
      "models--mistralai--Mistral-7B-v0.1\n",
      "models--robkayinto--vit-base-patch16-224-in21k-finetuned-lora-food101\n",
      "tmp3i5avt2i\n",
      "tmp560c_s3e\n",
      "tmp8is86yg8\n",
      "tmpea0zbrrj\n",
      "tmplm91b70r\n",
      "tmpni3ccozw\n",
      "tmpo224crmi\n",
      "version.txt\n"
     ]
    }
   ],
   "source": [
    "!ls /home/rob/Data2/huggingface/transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK ... now we have 310gb free ... keep going ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--meta-llama--Llama-2-13b-hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--meta-llama--Llama-2-7b-chat-hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--meta-llama--Llama-2-7b-hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--mistralai--Mistral-7B-Instruct-v0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--mistralai--Mistral-7B-v0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, have another looksee ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models--robkayinto--vit-base-patch16-224-in21k-finetuned-lora-food101\n",
      "tmp3i5avt2i\n",
      "tmp560c_s3e\n",
      "tmp8is86yg8\n",
      "tmpea0zbrrj\n",
      "tmplm91b70r\n",
      "tmpni3ccozw\n",
      "tmpo224crmi\n",
      "version.txt\n"
     ]
    }
   ],
   "source": [
    "!ls /home/rob/Data2/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/rob/Data2/huggingface/transformers/models--robkayinto--vit-base-patch16-224-in21k-finetuned-lora-food101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp3i5avt2i  tmp8is86yg8  tmplm91b70r  tmpo224crmi\n",
      "tmp560c_s3e  tmpea0zbrrj  tmpni3ccozw  version.txt\n"
     ]
    }
   ],
   "source": [
    "!ls /home/rob/Data2/huggingface/transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK ... there is now 393gb free ... ok, thats good enough for now ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
